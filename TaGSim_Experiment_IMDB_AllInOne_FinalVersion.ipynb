{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfp3rOdf-K2G",
        "outputId": "05251b59-b76d-4dae-93af-324cb3fbe200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import ast\n",
        "print(sys.executable)\n",
        "import os\n",
        "import random\n",
        "import networkx as nx\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# 1.nr 2.nid 3.er 4.eid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/519045752/TagSim/raw/master/IMDB.zip\n",
        "!unzip /content/IMDB.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MitQRFN_CBC",
        "outputId": "fdbe0ab8-0f6c-44dc-f0e6-81acb6c1b3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-05 13:41:10--  https://github.com/519045752/TagSim/raw/master/IMDB.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/519045752/TagSim/master/IMDB.zip [following]\n",
            "--2022-11-05 13:41:11--  https://raw.githubusercontent.com/519045752/TagSim/master/IMDB.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2579001 (2.5M) [application/zip]\n",
            "Saving to: ‘IMDB.zip’\n",
            "\n",
            "IMDB.zip            100%[===================>]   2.46M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-11-05 13:41:11 (36.6 MB/s) - ‘IMDB.zip’ saved [2579001/2579001]\n",
            "\n",
            "Archive:  /content/IMDB.zip\n",
            "   creating: generated/\n",
            "  inflating: generated/0_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1001_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1002_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1004_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1005_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1006_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1007_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1009_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1010_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1012_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1013_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1015_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1016_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1017_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1018_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1019_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/101_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1021_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1022_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1023_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1024_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1025_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1027_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1028_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1029_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1030_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1031_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1033_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1034_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1037_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1038_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1039_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/103_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1041_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1042_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1043_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1044_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1045_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1046_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1047_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1048_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1049_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/104_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1050_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1052_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1053_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1054_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1055_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1056_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1057_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1058_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1059_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/105_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1060_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1062_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1063_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1065_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1066_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1067_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1068_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/106_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1072_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1073_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1074_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1075_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1076_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1077_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1079_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/107_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1080_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1081_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1083_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1084_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1085_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1087_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1088_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1089_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/108_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1091_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1093_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1094_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1095_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1097_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1098_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1099_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/109_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/10_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1101_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1102_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1104_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1105_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1106_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1108_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1109_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/110_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1110_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1111_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1112_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1114_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1115_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1117_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1118_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1119_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1121_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1123_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1126_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1127_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1129_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/112_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1130_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1131_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1132_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1133_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1134_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1136_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1137_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1138_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1139_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/113_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1140_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1141_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1142_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1143_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1144_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1145_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1146_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1148_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1149_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/114_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1150_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1151_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1152_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1153_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1154_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1155_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1156_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1158_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1159_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/115_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1160_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1161_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1162_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1163_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1166_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1167_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1169_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1171_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1172_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1174_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1175_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1176_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1178_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1179_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/117_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1180_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1182_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1183_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1184_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1187_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1188_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1189_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1191_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1192_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1194_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1195_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1196_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1197_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1198_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1199_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/119_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1200_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1202_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1203_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1204_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1205_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1206_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1207_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1208_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1209_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/120_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1210_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1211_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1212_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1213_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1214_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1215_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1216_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1217_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1218_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/121_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1220_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1221_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1222_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1223_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1224_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1226_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1227_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1228_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1229_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/122_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1230_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1231_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1232_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1233_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1234_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1235_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1237_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1239_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/123_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1240_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1241_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1242_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1244_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1245_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1246_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1248_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/124_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1250_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1251_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1252_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1253_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1254_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1255_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1256_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1257_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1258_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1259_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/125_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1261_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1262_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1263_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1264_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1265_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1267_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1268_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/126_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1270_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1271_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1272_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1273_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1274_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1275_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1277_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1278_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1279_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1280_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1281_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1282_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1283_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1284_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1285_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1287_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1288_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1289_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1290_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1293_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1294_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1295_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1296_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1297_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1298_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1299_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/129_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/12_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1301_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1302_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1303_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1304_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1306_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1307_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1309_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/130_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1312_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1313_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1314_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1316_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1317_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1318_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1319_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1320_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1321_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1322_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1323_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1326_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1327_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1328_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1329_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/132_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1331_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1332_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1333_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1334_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1335_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1336_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1337_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1338_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1339_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/133_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1340_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1341_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1342_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1344_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1346_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1347_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1348_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1349_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/134_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1350_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1351_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1352_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1353_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1354_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1355_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1356_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1357_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1358_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1359_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/135_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1360_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1364_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1365_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1366_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1367_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1368_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1369_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/136_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1370_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1372_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1373_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1374_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1377_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1378_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1380_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1382_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1384_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1385_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1386_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1388_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1389_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1390_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1391_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1392_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1393_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1395_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1396_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1398_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1399_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/139_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/13_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1401_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1403_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1404_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1406_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1408_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1409_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/140_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1411_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1412_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1415_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1416_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1418_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1419_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/141_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1420_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1421_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1422_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1425_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1426_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1427_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1428_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1429_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1430_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1431_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1432_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1433_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1434_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1435_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1436_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1437_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1438_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1439_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/143_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1440_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1441_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1442_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1443_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1444_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/1445_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1446_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1448_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1449_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/144_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1450_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1451_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1452_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1453_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/1454_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1455_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1456_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1457_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1458_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1459_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1460_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1461_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1462_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/1463_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1464_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1467_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1468_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1469_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/146_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1470_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1471_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1472_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1473_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1474_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1476_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1477_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1478_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1479_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/147_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1480_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1481_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1483_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1484_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/1485_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1486_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1487_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1488_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1489_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/148_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1492_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/1493_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1494_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/1495_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1496_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1497_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/1498_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/1499_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/150_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/151_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/153_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/154_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/156_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/157_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/158_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/159_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/15_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/160_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/161_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/162_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/163_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/164_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/165_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/166_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/167_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/168_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/169_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/16_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/170_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/171_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/172_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/175_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/176_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/177_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/178_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/179_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/17_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/181_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/183_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/184_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/185_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/188_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/189_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/18_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/190_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/191_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/192_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/193_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/194_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/195_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/196_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/197_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/198_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/199_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/19_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/1_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/200_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/201_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/202_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/203_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/204_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/206_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/208_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/209_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/20_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/210_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/211_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/212_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/213_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/214_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/216_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/217_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/218_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/219_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/21_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/220_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/221_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/222_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/223_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/224_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/225_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/227_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/229_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/22_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/230_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/231_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/232_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/233_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/234_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/235_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/236_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/23_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/240_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/241_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/242_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/243_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/244_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/245_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/246_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/248_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/249_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/24_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/250_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/251_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/252_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/253_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/254_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/255_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/256_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/258_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/25_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/260_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/261_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/262_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/263_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/264_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/265_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/266_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/267_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/268_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/269_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/26_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/271_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/272_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/273_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/274_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/275_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/276_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/277_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/279_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/27_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/280_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/281_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/282_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/283_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/284_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/285_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/286_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/287_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/288_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/289_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/28_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/291_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/293_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/294_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/295_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/296_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/297_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/298_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/299_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/29_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/2_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/300_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/301_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/303_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/304_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/305_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/306_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/307_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/308_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/309_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/30_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/310_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/311_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/312_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/313_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/314_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/315_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/316_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/317_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/318_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/319_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/31_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/321_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/322_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/323_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/325_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/327_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/328_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/329_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/32_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/330_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/331_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/332_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/333_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/334_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/335_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/337_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/338_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/339_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/342_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/343_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/345_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/347_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/348_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/349_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/34_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/351_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/355_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/356_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/357_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/358_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/360_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/361_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/362_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/364_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/365_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/366_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/368_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/369_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/370_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/371_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/372_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/373_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/374_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/375_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/376_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/377_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/379_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/37_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/381_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/383_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/385_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/386_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/387_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/388_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/389_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/390_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/392_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/394_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/395_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/396_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/398_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/399_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/39_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/3_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/402_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/403_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/407_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/408_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/409_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/40_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/410_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/411_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/412_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/414_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/415_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/416_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/417_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/418_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/419_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/41_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/420_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/421_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/422_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/423_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/424_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/425_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/426_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/427_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/428_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/429_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/42_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/430_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/431_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/433_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/438_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/439_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/43_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/443_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/444_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/447_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/448_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/44_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/451_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/454_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/456_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/457_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/458_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/459_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/45_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/460_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/461_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/462_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/464_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/465_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/466_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/467_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/468_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/469_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/46_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/470_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/472_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/475_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/478_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/481_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/482_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/483_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/484_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/485_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/486_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/487_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/488_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/489_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/48_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/490_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/491_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/492_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/493_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/494_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/496_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/498_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/499_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/49_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/4_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/500_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/501_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/503_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/504_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/505_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/506_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/507_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/510_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/511_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/512_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/513_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/514_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/515_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/516_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/518_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/519_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/51_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/520_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/521_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/522_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/524_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/525_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/526_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/527_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/528_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/529_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/52_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/530_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/531_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/532_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/533_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/535_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/536_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/537_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/538_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/539_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/540_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/541_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/542_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/543_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/544_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/545_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/546_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/547_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/548_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/549_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/54_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/550_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/551_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/552_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/553_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/554_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/555_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/557_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/558_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/559_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/55_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/560_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/562_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/563_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/564_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/566_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/567_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/569_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/56_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/571_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/572_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/573_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/574_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/575_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/576_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/577_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/579_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/57_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/580_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/581_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/582_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/583_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/584_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/585_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/586_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/587_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/588_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/589_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/58_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/590_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/591_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/593_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/594_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/596_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/597_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/599_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/59_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/5_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/600_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/601_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/602_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/604_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/605_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/606_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/607_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/608_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/609_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/610_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/611_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/612_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/613_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/614_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/615_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/616_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/617_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/618_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/619_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/61_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/620_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/621_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/622_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/623_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/624_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/625_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/627_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/629_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/62_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/630_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/631_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/632_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/633_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/634_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/635_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/637_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/638_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/639_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/641_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/642_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/643_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/644_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/647_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/648_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/649_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/64_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/651_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/652_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/653_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/654_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/656_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/657_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/658_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/65_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/660_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/661_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/662_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/664_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/665_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/666_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/667_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/669_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/66_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/670_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/671_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/672_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/673_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/674_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/676_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/677_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/678_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/679_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/67_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/680_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/681_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/682_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/683_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/684_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/685_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/686_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/687_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/688_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/690_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/691_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/693_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/695_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/696_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/697_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/698_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/699_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/69_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/6_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/700_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/701_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/703_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/705_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/706_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/708_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/709_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/70_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/710_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/711_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/712_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/713_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/714_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/715_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/716_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/717_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/718_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/719_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/71_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/720_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/721_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/722_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/723_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/725_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/726_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/727_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/728_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/729_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/72_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/732_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/733_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/734_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/735_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/736_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/738_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/739_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/73_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/740_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/742_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/743_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/744_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/745_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/746_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/748_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/749_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/74_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/751_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/753_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/754_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/756_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/757_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/758_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/75_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/760_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/761_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/762_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/764_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/769_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/76_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/770_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/771_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/772_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/776_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/777_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/778_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/779_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/77_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/780_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/782_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/783_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/784_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/785_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/788_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/789_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/78_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/790_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/791_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/792_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/793_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/794_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/795_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/797_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/798_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/79_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/7_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/800_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/801_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/802_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/803_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/804_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/805_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/806_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/807_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/808_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/809_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/80_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/810_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/811_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/812_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/813_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/816_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/817_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/818_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/81_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/820_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/822_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/823_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/824_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/826_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/827_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/828_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/829_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/82_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/830_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/831_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/832_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/833_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/834_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/835_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/836_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/837_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/838_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/839_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/83_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/840_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/841_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/842_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/844_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/845_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/846_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/847_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/849_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/84_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/850_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/852_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/853_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/854_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/855_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/856_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/857_NR_0_NID_0_ER_0_EID_7.gexf  \n",
            "  inflating: generated/858_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/859_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/85_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/860_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/861_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/862_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/864_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/866_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/867_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/868_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/870_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/871_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/872_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/873_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/876_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/878_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/87_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/880_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/881_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/882_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/883_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/884_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/885_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/886_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/887_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/888_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/88_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/890_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/891_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/892_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/894_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/895_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/897_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/899_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/89_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/900_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/901_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/902_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/903_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/904_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/905_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/906_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/907_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/909_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/90_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/910_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/912_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/913_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/914_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/915_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/916_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/917_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/919_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/91_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/921_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/922_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/923_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/924_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/925_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/926_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/927_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/929_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/92_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/930_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/931_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/932_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/933_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/934_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/935_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/936_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/937_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/939_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/93_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/940_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/941_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/942_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/943_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/944_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/945_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/946_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/947_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/948_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/949_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/94_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/950_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/952_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/954_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/955_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/956_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/957_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/958_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/961_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/962_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/963_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/964_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/965_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/966_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/967_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/968_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/969_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/96_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/970_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/971_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/972_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/973_NR_0_NID_7_ER_0_EID_1.gexf  \n",
            "  inflating: generated/974_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/975_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/976_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/977_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/978_NR_0_NID_8_ER_0_EID_0.gexf  \n",
            "  inflating: generated/979_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/97_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/981_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/983_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/986_NR_0_NID_3_ER_0_EID_5.gexf  \n",
            "  inflating: generated/987_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/988_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/989_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/990_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/993_NR_0_NID_2_ER_0_EID_6.gexf  \n",
            "  inflating: generated/994_NR_0_NID_6_ER_0_EID_2.gexf  \n",
            "  inflating: generated/995_NR_0_NID_5_ER_0_EID_3.gexf  \n",
            "  inflating: generated/996_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/997_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/998_NR_0_NID_4_ER_0_EID_4.gexf  \n",
            "  inflating: generated/999_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "  inflating: generated/99_NR_0_NID_1_ER_0_EID_7.gexf  \n",
            "  inflating: generated/9_NR_0_NID_0_ER_0_EID_8.gexf  \n",
            "   creating: original/\n",
            "  inflating: original/0.gexf         \n",
            "  inflating: original/1.gexf         \n",
            "  inflating: original/10.gexf        \n",
            "  inflating: original/1001.gexf      \n",
            "  inflating: original/1002.gexf      \n",
            "  inflating: original/1004.gexf      \n",
            "  inflating: original/1005.gexf      \n",
            "  inflating: original/1006.gexf      \n",
            "  inflating: original/1007.gexf      \n",
            "  inflating: original/1009.gexf      \n",
            "  inflating: original/101.gexf       \n",
            "  inflating: original/1010.gexf      \n",
            "  inflating: original/1012.gexf      \n",
            "  inflating: original/1013.gexf      \n",
            "  inflating: original/1015.gexf      \n",
            "  inflating: original/1016.gexf      \n",
            "  inflating: original/1017.gexf      \n",
            "  inflating: original/1018.gexf      \n",
            "  inflating: original/1019.gexf      \n",
            "  inflating: original/1021.gexf      \n",
            "  inflating: original/1022.gexf      \n",
            "  inflating: original/1023.gexf      \n",
            "  inflating: original/1024.gexf      \n",
            "  inflating: original/1025.gexf      \n",
            "  inflating: original/1027.gexf      \n",
            "  inflating: original/1028.gexf      \n",
            "  inflating: original/1029.gexf      \n",
            "  inflating: original/103.gexf       \n",
            "  inflating: original/1030.gexf      \n",
            "  inflating: original/1031.gexf      \n",
            "  inflating: original/1033.gexf      \n",
            "  inflating: original/1034.gexf      \n",
            "  inflating: original/1037.gexf      \n",
            "  inflating: original/1038.gexf      \n",
            "  inflating: original/1039.gexf      \n",
            "  inflating: original/104.gexf       \n",
            "  inflating: original/1041.gexf      \n",
            "  inflating: original/1042.gexf      \n",
            "  inflating: original/1043.gexf      \n",
            "  inflating: original/1044.gexf      \n",
            "  inflating: original/1045.gexf      \n",
            "  inflating: original/1046.gexf      \n",
            "  inflating: original/1047.gexf      \n",
            "  inflating: original/1048.gexf      \n",
            "  inflating: original/1049.gexf      \n",
            "  inflating: original/105.gexf       \n",
            "  inflating: original/1050.gexf      \n",
            "  inflating: original/1052.gexf      \n",
            "  inflating: original/1053.gexf      \n",
            "  inflating: original/1054.gexf      \n",
            "  inflating: original/1055.gexf      \n",
            "  inflating: original/1056.gexf      \n",
            "  inflating: original/1057.gexf      \n",
            "  inflating: original/1058.gexf      \n",
            "  inflating: original/1059.gexf      \n",
            "  inflating: original/106.gexf       \n",
            "  inflating: original/1060.gexf      \n",
            "  inflating: original/1062.gexf      \n",
            "  inflating: original/1063.gexf      \n",
            "  inflating: original/1065.gexf      \n",
            "  inflating: original/1066.gexf      \n",
            "  inflating: original/1067.gexf      \n",
            "  inflating: original/1068.gexf      \n",
            "  inflating: original/107.gexf       \n",
            "  inflating: original/1072.gexf      \n",
            "  inflating: original/1073.gexf      \n",
            "  inflating: original/1074.gexf      \n",
            "  inflating: original/1075.gexf      \n",
            "  inflating: original/1076.gexf      \n",
            "  inflating: original/1077.gexf      \n",
            "  inflating: original/1079.gexf      \n",
            "  inflating: original/108.gexf       \n",
            "  inflating: original/1080.gexf      \n",
            "  inflating: original/1081.gexf      \n",
            "  inflating: original/1083.gexf      \n",
            "  inflating: original/1084.gexf      \n",
            "  inflating: original/1085.gexf      \n",
            "  inflating: original/1087.gexf      \n",
            "  inflating: original/1088.gexf      \n",
            "  inflating: original/1089.gexf      \n",
            "  inflating: original/109.gexf       \n",
            "  inflating: original/1091.gexf      \n",
            "  inflating: original/1093.gexf      \n",
            "  inflating: original/1094.gexf      \n",
            "  inflating: original/1095.gexf      \n",
            "  inflating: original/1097.gexf      \n",
            "  inflating: original/1098.gexf      \n",
            "  inflating: original/1099.gexf      \n",
            "  inflating: original/110.gexf       \n",
            "  inflating: original/1101.gexf      \n",
            "  inflating: original/1102.gexf      \n",
            "  inflating: original/1104.gexf      \n",
            "  inflating: original/1105.gexf      \n",
            "  inflating: original/1106.gexf      \n",
            "  inflating: original/1108.gexf      \n",
            "  inflating: original/1109.gexf      \n",
            "  inflating: original/1110.gexf      \n",
            "  inflating: original/1111.gexf      \n",
            "  inflating: original/1112.gexf      \n",
            "  inflating: original/1114.gexf      \n",
            "  inflating: original/1115.gexf      \n",
            "  inflating: original/1117.gexf      \n",
            "  inflating: original/1118.gexf      \n",
            "  inflating: original/1119.gexf      \n",
            "  inflating: original/112.gexf       \n",
            "  inflating: original/1121.gexf      \n",
            "  inflating: original/1123.gexf      \n",
            "  inflating: original/1126.gexf      \n",
            "  inflating: original/1127.gexf      \n",
            "  inflating: original/1129.gexf      \n",
            "  inflating: original/113.gexf       \n",
            "  inflating: original/1130.gexf      \n",
            "  inflating: original/1131.gexf      \n",
            "  inflating: original/1132.gexf      \n",
            "  inflating: original/1133.gexf      \n",
            "  inflating: original/1134.gexf      \n",
            "  inflating: original/1136.gexf      \n",
            "  inflating: original/1137.gexf      \n",
            "  inflating: original/1138.gexf      \n",
            "  inflating: original/1139.gexf      \n",
            "  inflating: original/114.gexf       \n",
            "  inflating: original/1140.gexf      \n",
            "  inflating: original/1141.gexf      \n",
            "  inflating: original/1142.gexf      \n",
            "  inflating: original/1143.gexf      \n",
            "  inflating: original/1144.gexf      \n",
            "  inflating: original/1145.gexf      \n",
            "  inflating: original/1146.gexf      \n",
            "  inflating: original/1148.gexf      \n",
            "  inflating: original/1149.gexf      \n",
            "  inflating: original/115.gexf       \n",
            "  inflating: original/1150.gexf      \n",
            "  inflating: original/1151.gexf      \n",
            "  inflating: original/1152.gexf      \n",
            "  inflating: original/1153.gexf      \n",
            "  inflating: original/1154.gexf      \n",
            "  inflating: original/1155.gexf      \n",
            "  inflating: original/1156.gexf      \n",
            "  inflating: original/1158.gexf      \n",
            "  inflating: original/1159.gexf      \n",
            "  inflating: original/1160.gexf      \n",
            "  inflating: original/1161.gexf      \n",
            "  inflating: original/1162.gexf      \n",
            "  inflating: original/1163.gexf      \n",
            "  inflating: original/1166.gexf      \n",
            "  inflating: original/1167.gexf      \n",
            "  inflating: original/1169.gexf      \n",
            "  inflating: original/117.gexf       \n",
            "  inflating: original/1171.gexf      \n",
            "  inflating: original/1172.gexf      \n",
            "  inflating: original/1174.gexf      \n",
            "  inflating: original/1175.gexf      \n",
            "  inflating: original/1176.gexf      \n",
            "  inflating: original/1178.gexf      \n",
            "  inflating: original/1179.gexf      \n",
            "  inflating: original/1180.gexf      \n",
            "  inflating: original/1182.gexf      \n",
            "  inflating: original/1183.gexf      \n",
            "  inflating: original/1184.gexf      \n",
            "  inflating: original/1187.gexf      \n",
            "  inflating: original/1188.gexf      \n",
            "  inflating: original/1189.gexf      \n",
            "  inflating: original/119.gexf       \n",
            "  inflating: original/1191.gexf      \n",
            "  inflating: original/1192.gexf      \n",
            "  inflating: original/1194.gexf      \n",
            "  inflating: original/1195.gexf      \n",
            "  inflating: original/1196.gexf      \n",
            "  inflating: original/1197.gexf      \n",
            "  inflating: original/1198.gexf      \n",
            "  inflating: original/1199.gexf      \n",
            "  inflating: original/12.gexf        \n",
            "  inflating: original/120.gexf       \n",
            "  inflating: original/1200.gexf      \n",
            "  inflating: original/1202.gexf      \n",
            "  inflating: original/1203.gexf      \n",
            "  inflating: original/1204.gexf      \n",
            "  inflating: original/1205.gexf      \n",
            "  inflating: original/1206.gexf      \n",
            "  inflating: original/1207.gexf      \n",
            "  inflating: original/1208.gexf      \n",
            "  inflating: original/1209.gexf      \n",
            "  inflating: original/121.gexf       \n",
            "  inflating: original/1210.gexf      \n",
            "  inflating: original/1211.gexf      \n",
            "  inflating: original/1212.gexf      \n",
            "  inflating: original/1213.gexf      \n",
            "  inflating: original/1214.gexf      \n",
            "  inflating: original/1215.gexf      \n",
            "  inflating: original/1216.gexf      \n",
            "  inflating: original/1217.gexf      \n",
            "  inflating: original/1218.gexf      \n",
            "  inflating: original/122.gexf       \n",
            "  inflating: original/1220.gexf      \n",
            "  inflating: original/1221.gexf      \n",
            "  inflating: original/1222.gexf      \n",
            "  inflating: original/1223.gexf      \n",
            "  inflating: original/1224.gexf      \n",
            "  inflating: original/1226.gexf      \n",
            "  inflating: original/1227.gexf      \n",
            "  inflating: original/1228.gexf      \n",
            "  inflating: original/1229.gexf      \n",
            "  inflating: original/123.gexf       \n",
            "  inflating: original/1230.gexf      \n",
            "  inflating: original/1231.gexf      \n",
            "  inflating: original/1232.gexf      \n",
            "  inflating: original/1233.gexf      \n",
            "  inflating: original/1234.gexf      \n",
            "  inflating: original/1235.gexf      \n",
            "  inflating: original/1237.gexf      \n",
            "  inflating: original/1239.gexf      \n",
            "  inflating: original/124.gexf       \n",
            "  inflating: original/1240.gexf      \n",
            "  inflating: original/1241.gexf      \n",
            "  inflating: original/1242.gexf      \n",
            "  inflating: original/1244.gexf      \n",
            "  inflating: original/1245.gexf      \n",
            "  inflating: original/1246.gexf      \n",
            "  inflating: original/1248.gexf      \n",
            "  inflating: original/125.gexf       \n",
            "  inflating: original/1250.gexf      \n",
            "  inflating: original/1251.gexf      \n",
            "  inflating: original/1252.gexf      \n",
            "  inflating: original/1253.gexf      \n",
            "  inflating: original/1254.gexf      \n",
            "  inflating: original/1255.gexf      \n",
            "  inflating: original/1256.gexf      \n",
            "  inflating: original/1257.gexf      \n",
            "  inflating: original/1258.gexf      \n",
            "  inflating: original/1259.gexf      \n",
            "  inflating: original/126.gexf       \n",
            "  inflating: original/1261.gexf      \n",
            "  inflating: original/1262.gexf      \n",
            "  inflating: original/1263.gexf      \n",
            "  inflating: original/1264.gexf      \n",
            "  inflating: original/1265.gexf      \n",
            "  inflating: original/1267.gexf      \n",
            "  inflating: original/1268.gexf      \n",
            "  inflating: original/1270.gexf      \n",
            "  inflating: original/1271.gexf      \n",
            "  inflating: original/1272.gexf      \n",
            "  inflating: original/1273.gexf      \n",
            "  inflating: original/1274.gexf      \n",
            "  inflating: original/1275.gexf      \n",
            "  inflating: original/1277.gexf      \n",
            "  inflating: original/1278.gexf      \n",
            "  inflating: original/1279.gexf      \n",
            "  inflating: original/1280.gexf      \n",
            "  inflating: original/1281.gexf      \n",
            "  inflating: original/1282.gexf      \n",
            "  inflating: original/1283.gexf      \n",
            "  inflating: original/1284.gexf      \n",
            "  inflating: original/1285.gexf      \n",
            "  inflating: original/1287.gexf      \n",
            "  inflating: original/1288.gexf      \n",
            "  inflating: original/1289.gexf      \n",
            "  inflating: original/129.gexf       \n",
            "  inflating: original/1290.gexf      \n",
            "  inflating: original/1293.gexf      \n",
            "  inflating: original/1294.gexf      \n",
            "  inflating: original/1295.gexf      \n",
            "  inflating: original/1296.gexf      \n",
            "  inflating: original/1297.gexf      \n",
            "  inflating: original/1298.gexf      \n",
            "  inflating: original/1299.gexf      \n",
            "  inflating: original/13.gexf        \n",
            "  inflating: original/130.gexf       \n",
            "  inflating: original/1301.gexf      \n",
            "  inflating: original/1302.gexf      \n",
            "  inflating: original/1303.gexf      \n",
            "  inflating: original/1304.gexf      \n",
            "  inflating: original/1306.gexf      \n",
            "  inflating: original/1307.gexf      \n",
            "  inflating: original/1309.gexf      \n",
            "  inflating: original/1312.gexf      \n",
            "  inflating: original/1313.gexf      \n",
            "  inflating: original/1314.gexf      \n",
            "  inflating: original/1316.gexf      \n",
            "  inflating: original/1317.gexf      \n",
            "  inflating: original/1318.gexf      \n",
            "  inflating: original/1319.gexf      \n",
            "  inflating: original/132.gexf       \n",
            "  inflating: original/1320.gexf      \n",
            "  inflating: original/1321.gexf      \n",
            "  inflating: original/1322.gexf      \n",
            "  inflating: original/1323.gexf      \n",
            "  inflating: original/1326.gexf      \n",
            "  inflating: original/1327.gexf      \n",
            "  inflating: original/1328.gexf      \n",
            "  inflating: original/1329.gexf      \n",
            "  inflating: original/133.gexf       \n",
            "  inflating: original/1331.gexf      \n",
            "  inflating: original/1332.gexf      \n",
            "  inflating: original/1333.gexf      \n",
            "  inflating: original/1334.gexf      \n",
            "  inflating: original/1335.gexf      \n",
            "  inflating: original/1336.gexf      \n",
            "  inflating: original/1337.gexf      \n",
            "  inflating: original/1338.gexf      \n",
            "  inflating: original/1339.gexf      \n",
            "  inflating: original/134.gexf       \n",
            "  inflating: original/1340.gexf      \n",
            "  inflating: original/1341.gexf      \n",
            "  inflating: original/1342.gexf      \n",
            "  inflating: original/1344.gexf      \n",
            "  inflating: original/1346.gexf      \n",
            "  inflating: original/1347.gexf      \n",
            "  inflating: original/1348.gexf      \n",
            "  inflating: original/1349.gexf      \n",
            "  inflating: original/135.gexf       \n",
            "  inflating: original/1350.gexf      \n",
            "  inflating: original/1351.gexf      \n",
            "  inflating: original/1352.gexf      \n",
            "  inflating: original/1353.gexf      \n",
            "  inflating: original/1354.gexf      \n",
            "  inflating: original/1355.gexf      \n",
            "  inflating: original/1356.gexf      \n",
            "  inflating: original/1357.gexf      \n",
            "  inflating: original/1358.gexf      \n",
            "  inflating: original/1359.gexf      \n",
            "  inflating: original/136.gexf       \n",
            "  inflating: original/1360.gexf      \n",
            "  inflating: original/1364.gexf      \n",
            "  inflating: original/1365.gexf      \n",
            "  inflating: original/1366.gexf      \n",
            "  inflating: original/1367.gexf      \n",
            "  inflating: original/1368.gexf      \n",
            "  inflating: original/1369.gexf      \n",
            "  inflating: original/1370.gexf      \n",
            "  inflating: original/1372.gexf      \n",
            "  inflating: original/1373.gexf      \n",
            "  inflating: original/1374.gexf      \n",
            "  inflating: original/1377.gexf      \n",
            "  inflating: original/1378.gexf      \n",
            "  inflating: original/1380.gexf      \n",
            "  inflating: original/1382.gexf      \n",
            "  inflating: original/1384.gexf      \n",
            "  inflating: original/1385.gexf      \n",
            "  inflating: original/1386.gexf      \n",
            "  inflating: original/1388.gexf      \n",
            "  inflating: original/1389.gexf      \n",
            "  inflating: original/139.gexf       \n",
            "  inflating: original/1390.gexf      \n",
            "  inflating: original/1391.gexf      \n",
            "  inflating: original/1392.gexf      \n",
            "  inflating: original/1393.gexf      \n",
            "  inflating: original/1395.gexf      \n",
            "  inflating: original/1396.gexf      \n",
            "  inflating: original/1398.gexf      \n",
            "  inflating: original/1399.gexf      \n",
            "  inflating: original/140.gexf       \n",
            "  inflating: original/1401.gexf      \n",
            "  inflating: original/1403.gexf      \n",
            "  inflating: original/1404.gexf      \n",
            "  inflating: original/1406.gexf      \n",
            "  inflating: original/1408.gexf      \n",
            "  inflating: original/1409.gexf      \n",
            "  inflating: original/141.gexf       \n",
            "  inflating: original/1411.gexf      \n",
            "  inflating: original/1412.gexf      \n",
            "  inflating: original/1415.gexf      \n",
            "  inflating: original/1416.gexf      \n",
            "  inflating: original/1418.gexf      \n",
            "  inflating: original/1419.gexf      \n",
            "  inflating: original/1420.gexf      \n",
            "  inflating: original/1421.gexf      \n",
            "  inflating: original/1422.gexf      \n",
            "  inflating: original/1425.gexf      \n",
            "  inflating: original/1426.gexf      \n",
            "  inflating: original/1427.gexf      \n",
            "  inflating: original/1428.gexf      \n",
            "  inflating: original/1429.gexf      \n",
            "  inflating: original/143.gexf       \n",
            "  inflating: original/1430.gexf      \n",
            "  inflating: original/1431.gexf      \n",
            "  inflating: original/1432.gexf      \n",
            "  inflating: original/1433.gexf      \n",
            "  inflating: original/1434.gexf      \n",
            "  inflating: original/1435.gexf      \n",
            "  inflating: original/1436.gexf      \n",
            "  inflating: original/1437.gexf      \n",
            "  inflating: original/1438.gexf      \n",
            "  inflating: original/1439.gexf      \n",
            "  inflating: original/144.gexf       \n",
            "  inflating: original/1440.gexf      \n",
            "  inflating: original/1441.gexf      \n",
            "  inflating: original/1442.gexf      \n",
            "  inflating: original/1443.gexf      \n",
            "  inflating: original/1444.gexf      \n",
            "  inflating: original/1445.gexf      \n",
            "  inflating: original/1446.gexf      \n",
            "  inflating: original/1448.gexf      \n",
            "  inflating: original/1449.gexf      \n",
            "  inflating: original/1450.gexf      \n",
            "  inflating: original/1451.gexf      \n",
            "  inflating: original/1452.gexf      \n",
            "  inflating: original/1453.gexf      \n",
            "  inflating: original/1454.gexf      \n",
            "  inflating: original/1455.gexf      \n",
            "  inflating: original/1456.gexf      \n",
            "  inflating: original/1457.gexf      \n",
            "  inflating: original/1458.gexf      \n",
            "  inflating: original/1459.gexf      \n",
            "  inflating: original/146.gexf       \n",
            "  inflating: original/1460.gexf      \n",
            "  inflating: original/1461.gexf      \n",
            "  inflating: original/1462.gexf      \n",
            "  inflating: original/1463.gexf      \n",
            "  inflating: original/1464.gexf      \n",
            "  inflating: original/1467.gexf      \n",
            "  inflating: original/1468.gexf      \n",
            "  inflating: original/1469.gexf      \n",
            "  inflating: original/147.gexf       \n",
            "  inflating: original/1470.gexf      \n",
            "  inflating: original/1471.gexf      \n",
            "  inflating: original/1472.gexf      \n",
            "  inflating: original/1473.gexf      \n",
            "  inflating: original/1474.gexf      \n",
            "  inflating: original/1476.gexf      \n",
            "  inflating: original/1477.gexf      \n",
            "  inflating: original/1478.gexf      \n",
            "  inflating: original/1479.gexf      \n",
            "  inflating: original/148.gexf       \n",
            "  inflating: original/1480.gexf      \n",
            "  inflating: original/1481.gexf      \n",
            "  inflating: original/1483.gexf      \n",
            "  inflating: original/1484.gexf      \n",
            "  inflating: original/1485.gexf      \n",
            "  inflating: original/1486.gexf      \n",
            "  inflating: original/1487.gexf      \n",
            "  inflating: original/1488.gexf      \n",
            "  inflating: original/1489.gexf      \n",
            "  inflating: original/1492.gexf      \n",
            "  inflating: original/1493.gexf      \n",
            "  inflating: original/1494.gexf      \n",
            "  inflating: original/1495.gexf      \n",
            "  inflating: original/1496.gexf      \n",
            "  inflating: original/1497.gexf      \n",
            "  inflating: original/1498.gexf      \n",
            "  inflating: original/1499.gexf      \n",
            "  inflating: original/15.gexf        \n",
            "  inflating: original/150.gexf       \n",
            "  inflating: original/151.gexf       \n",
            "  inflating: original/153.gexf       \n",
            "  inflating: original/154.gexf       \n",
            "  inflating: original/156.gexf       \n",
            "  inflating: original/157.gexf       \n",
            "  inflating: original/158.gexf       \n",
            "  inflating: original/159.gexf       \n",
            "  inflating: original/16.gexf        \n",
            "  inflating: original/160.gexf       \n",
            "  inflating: original/161.gexf       \n",
            "  inflating: original/162.gexf       \n",
            "  inflating: original/163.gexf       \n",
            "  inflating: original/164.gexf       \n",
            "  inflating: original/165.gexf       \n",
            "  inflating: original/166.gexf       \n",
            "  inflating: original/167.gexf       \n",
            "  inflating: original/168.gexf       \n",
            "  inflating: original/169.gexf       \n",
            "  inflating: original/17.gexf        \n",
            "  inflating: original/170.gexf       \n",
            "  inflating: original/171.gexf       \n",
            "  inflating: original/172.gexf       \n",
            "  inflating: original/175.gexf       \n",
            "  inflating: original/176.gexf       \n",
            "  inflating: original/177.gexf       \n",
            "  inflating: original/178.gexf       \n",
            "  inflating: original/179.gexf       \n",
            "  inflating: original/18.gexf        \n",
            "  inflating: original/181.gexf       \n",
            "  inflating: original/183.gexf       \n",
            "  inflating: original/184.gexf       \n",
            "  inflating: original/185.gexf       \n",
            "  inflating: original/188.gexf       \n",
            "  inflating: original/189.gexf       \n",
            "  inflating: original/19.gexf        \n",
            "  inflating: original/190.gexf       \n",
            "  inflating: original/191.gexf       \n",
            "  inflating: original/192.gexf       \n",
            "  inflating: original/193.gexf       \n",
            "  inflating: original/194.gexf       \n",
            "  inflating: original/195.gexf       \n",
            "  inflating: original/196.gexf       \n",
            "  inflating: original/197.gexf       \n",
            "  inflating: original/198.gexf       \n",
            "  inflating: original/199.gexf       \n",
            "  inflating: original/2.gexf         \n",
            "  inflating: original/20.gexf        \n",
            "  inflating: original/200.gexf       \n",
            "  inflating: original/201.gexf       \n",
            "  inflating: original/202.gexf       \n",
            "  inflating: original/203.gexf       \n",
            "  inflating: original/204.gexf       \n",
            "  inflating: original/206.gexf       \n",
            "  inflating: original/208.gexf       \n",
            "  inflating: original/209.gexf       \n",
            "  inflating: original/21.gexf        \n",
            "  inflating: original/210.gexf       \n",
            "  inflating: original/211.gexf       \n",
            "  inflating: original/212.gexf       \n",
            "  inflating: original/213.gexf       \n",
            "  inflating: original/214.gexf       \n",
            "  inflating: original/216.gexf       \n",
            "  inflating: original/217.gexf       \n",
            "  inflating: original/218.gexf       \n",
            "  inflating: original/219.gexf       \n",
            "  inflating: original/22.gexf        \n",
            "  inflating: original/220.gexf       \n",
            "  inflating: original/221.gexf       \n",
            "  inflating: original/222.gexf       \n",
            "  inflating: original/223.gexf       \n",
            "  inflating: original/224.gexf       \n",
            "  inflating: original/225.gexf       \n",
            "  inflating: original/227.gexf       \n",
            "  inflating: original/229.gexf       \n",
            "  inflating: original/23.gexf        \n",
            "  inflating: original/230.gexf       \n",
            "  inflating: original/231.gexf       \n",
            "  inflating: original/232.gexf       \n",
            "  inflating: original/233.gexf       \n",
            "  inflating: original/234.gexf       \n",
            "  inflating: original/235.gexf       \n",
            "  inflating: original/236.gexf       \n",
            "  inflating: original/24.gexf        \n",
            "  inflating: original/240.gexf       \n",
            "  inflating: original/241.gexf       \n",
            "  inflating: original/242.gexf       \n",
            "  inflating: original/243.gexf       \n",
            "  inflating: original/244.gexf       \n",
            "  inflating: original/245.gexf       \n",
            "  inflating: original/246.gexf       \n",
            "  inflating: original/248.gexf       \n",
            "  inflating: original/249.gexf       \n",
            "  inflating: original/25.gexf        \n",
            "  inflating: original/250.gexf       \n",
            "  inflating: original/251.gexf       \n",
            "  inflating: original/252.gexf       \n",
            "  inflating: original/253.gexf       \n",
            "  inflating: original/254.gexf       \n",
            "  inflating: original/255.gexf       \n",
            "  inflating: original/256.gexf       \n",
            "  inflating: original/258.gexf       \n",
            "  inflating: original/26.gexf        \n",
            "  inflating: original/260.gexf       \n",
            "  inflating: original/261.gexf       \n",
            "  inflating: original/262.gexf       \n",
            "  inflating: original/263.gexf       \n",
            "  inflating: original/264.gexf       \n",
            "  inflating: original/265.gexf       \n",
            "  inflating: original/266.gexf       \n",
            "  inflating: original/267.gexf       \n",
            "  inflating: original/268.gexf       \n",
            "  inflating: original/269.gexf       \n",
            "  inflating: original/27.gexf        \n",
            "  inflating: original/271.gexf       \n",
            "  inflating: original/272.gexf       \n",
            "  inflating: original/273.gexf       \n",
            "  inflating: original/274.gexf       \n",
            "  inflating: original/275.gexf       \n",
            "  inflating: original/276.gexf       \n",
            "  inflating: original/277.gexf       \n",
            "  inflating: original/279.gexf       \n",
            "  inflating: original/28.gexf        \n",
            "  inflating: original/280.gexf       \n",
            "  inflating: original/281.gexf       \n",
            "  inflating: original/282.gexf       \n",
            "  inflating: original/283.gexf       \n",
            "  inflating: original/284.gexf       \n",
            "  inflating: original/285.gexf       \n",
            "  inflating: original/286.gexf       \n",
            "  inflating: original/287.gexf       \n",
            "  inflating: original/288.gexf       \n",
            "  inflating: original/289.gexf       \n",
            "  inflating: original/29.gexf        \n",
            "  inflating: original/291.gexf       \n",
            "  inflating: original/293.gexf       \n",
            "  inflating: original/294.gexf       \n",
            "  inflating: original/295.gexf       \n",
            "  inflating: original/296.gexf       \n",
            "  inflating: original/297.gexf       \n",
            "  inflating: original/298.gexf       \n",
            "  inflating: original/299.gexf       \n",
            "  inflating: original/3.gexf         \n",
            "  inflating: original/30.gexf        \n",
            "  inflating: original/300.gexf       \n",
            "  inflating: original/301.gexf       \n",
            "  inflating: original/303.gexf       \n",
            "  inflating: original/304.gexf       \n",
            "  inflating: original/305.gexf       \n",
            "  inflating: original/306.gexf       \n",
            "  inflating: original/307.gexf       \n",
            "  inflating: original/308.gexf       \n",
            "  inflating: original/309.gexf       \n",
            "  inflating: original/31.gexf        \n",
            "  inflating: original/310.gexf       \n",
            "  inflating: original/311.gexf       \n",
            "  inflating: original/312.gexf       \n",
            "  inflating: original/313.gexf       \n",
            "  inflating: original/314.gexf       \n",
            "  inflating: original/315.gexf       \n",
            "  inflating: original/316.gexf       \n",
            "  inflating: original/317.gexf       \n",
            "  inflating: original/318.gexf       \n",
            "  inflating: original/319.gexf       \n",
            "  inflating: original/32.gexf        \n",
            "  inflating: original/321.gexf       \n",
            "  inflating: original/322.gexf       \n",
            "  inflating: original/323.gexf       \n",
            "  inflating: original/325.gexf       \n",
            "  inflating: original/327.gexf       \n",
            "  inflating: original/328.gexf       \n",
            "  inflating: original/329.gexf       \n",
            "  inflating: original/330.gexf       \n",
            "  inflating: original/331.gexf       \n",
            "  inflating: original/332.gexf       \n",
            "  inflating: original/333.gexf       \n",
            "  inflating: original/334.gexf       \n",
            "  inflating: original/335.gexf       \n",
            "  inflating: original/337.gexf       \n",
            "  inflating: original/338.gexf       \n",
            "  inflating: original/339.gexf       \n",
            "  inflating: original/34.gexf        \n",
            "  inflating: original/342.gexf       \n",
            "  inflating: original/343.gexf       \n",
            "  inflating: original/345.gexf       \n",
            "  inflating: original/347.gexf       \n",
            "  inflating: original/348.gexf       \n",
            "  inflating: original/349.gexf       \n",
            "  inflating: original/351.gexf       \n",
            "  inflating: original/355.gexf       \n",
            "  inflating: original/356.gexf       \n",
            "  inflating: original/357.gexf       \n",
            "  inflating: original/358.gexf       \n",
            "  inflating: original/360.gexf       \n",
            "  inflating: original/361.gexf       \n",
            "  inflating: original/362.gexf       \n",
            "  inflating: original/364.gexf       \n",
            "  inflating: original/365.gexf       \n",
            "  inflating: original/366.gexf       \n",
            "  inflating: original/368.gexf       \n",
            "  inflating: original/369.gexf       \n",
            "  inflating: original/37.gexf        \n",
            "  inflating: original/370.gexf       \n",
            "  inflating: original/371.gexf       \n",
            "  inflating: original/372.gexf       \n",
            "  inflating: original/373.gexf       \n",
            "  inflating: original/374.gexf       \n",
            "  inflating: original/375.gexf       \n",
            "  inflating: original/376.gexf       \n",
            "  inflating: original/377.gexf       \n",
            "  inflating: original/379.gexf       \n",
            "  inflating: original/381.gexf       \n",
            "  inflating: original/383.gexf       \n",
            "  inflating: original/385.gexf       \n",
            "  inflating: original/386.gexf       \n",
            "  inflating: original/387.gexf       \n",
            "  inflating: original/388.gexf       \n",
            "  inflating: original/389.gexf       \n",
            "  inflating: original/39.gexf        \n",
            "  inflating: original/390.gexf       \n",
            "  inflating: original/392.gexf       \n",
            "  inflating: original/394.gexf       \n",
            "  inflating: original/395.gexf       \n",
            "  inflating: original/396.gexf       \n",
            "  inflating: original/398.gexf       \n",
            "  inflating: original/399.gexf       \n",
            "  inflating: original/4.gexf         \n",
            "  inflating: original/40.gexf        \n",
            "  inflating: original/402.gexf       \n",
            "  inflating: original/403.gexf       \n",
            "  inflating: original/407.gexf       \n",
            "  inflating: original/408.gexf       \n",
            "  inflating: original/409.gexf       \n",
            "  inflating: original/41.gexf        \n",
            "  inflating: original/410.gexf       \n",
            "  inflating: original/411.gexf       \n",
            "  inflating: original/412.gexf       \n",
            "  inflating: original/414.gexf       \n",
            "  inflating: original/415.gexf       \n",
            "  inflating: original/416.gexf       \n",
            "  inflating: original/417.gexf       \n",
            "  inflating: original/418.gexf       \n",
            "  inflating: original/419.gexf       \n",
            "  inflating: original/42.gexf        \n",
            "  inflating: original/420.gexf       \n",
            "  inflating: original/421.gexf       \n",
            "  inflating: original/422.gexf       \n",
            "  inflating: original/423.gexf       \n",
            "  inflating: original/424.gexf       \n",
            "  inflating: original/425.gexf       \n",
            "  inflating: original/426.gexf       \n",
            "  inflating: original/427.gexf       \n",
            "  inflating: original/428.gexf       \n",
            "  inflating: original/429.gexf       \n",
            "  inflating: original/43.gexf        \n",
            "  inflating: original/430.gexf       \n",
            "  inflating: original/431.gexf       \n",
            "  inflating: original/433.gexf       \n",
            "  inflating: original/438.gexf       \n",
            "  inflating: original/439.gexf       \n",
            "  inflating: original/44.gexf        \n",
            "  inflating: original/443.gexf       \n",
            "  inflating: original/444.gexf       \n",
            "  inflating: original/447.gexf       \n",
            "  inflating: original/448.gexf       \n",
            "  inflating: original/45.gexf        \n",
            "  inflating: original/451.gexf       \n",
            "  inflating: original/454.gexf       \n",
            "  inflating: original/456.gexf       \n",
            "  inflating: original/457.gexf       \n",
            "  inflating: original/458.gexf       \n",
            "  inflating: original/459.gexf       \n",
            "  inflating: original/46.gexf        \n",
            "  inflating: original/460.gexf       \n",
            "  inflating: original/461.gexf       \n",
            "  inflating: original/462.gexf       \n",
            "  inflating: original/464.gexf       \n",
            "  inflating: original/465.gexf       \n",
            "  inflating: original/466.gexf       \n",
            "  inflating: original/467.gexf       \n",
            "  inflating: original/468.gexf       \n",
            "  inflating: original/469.gexf       \n",
            "  inflating: original/470.gexf       \n",
            "  inflating: original/472.gexf       \n",
            "  inflating: original/475.gexf       \n",
            "  inflating: original/478.gexf       \n",
            "  inflating: original/48.gexf        \n",
            "  inflating: original/481.gexf       \n",
            "  inflating: original/482.gexf       \n",
            "  inflating: original/483.gexf       \n",
            "  inflating: original/484.gexf       \n",
            "  inflating: original/485.gexf       \n",
            "  inflating: original/486.gexf       \n",
            "  inflating: original/487.gexf       \n",
            "  inflating: original/488.gexf       \n",
            "  inflating: original/489.gexf       \n",
            "  inflating: original/49.gexf        \n",
            "  inflating: original/490.gexf       \n",
            "  inflating: original/491.gexf       \n",
            "  inflating: original/492.gexf       \n",
            "  inflating: original/493.gexf       \n",
            "  inflating: original/494.gexf       \n",
            "  inflating: original/496.gexf       \n",
            "  inflating: original/498.gexf       \n",
            "  inflating: original/499.gexf       \n",
            "  inflating: original/5.gexf         \n",
            "  inflating: original/500.gexf       \n",
            "  inflating: original/501.gexf       \n",
            "  inflating: original/503.gexf       \n",
            "  inflating: original/504.gexf       \n",
            "  inflating: original/505.gexf       \n",
            "  inflating: original/506.gexf       \n",
            "  inflating: original/507.gexf       \n",
            "  inflating: original/51.gexf        \n",
            "  inflating: original/510.gexf       \n",
            "  inflating: original/511.gexf       \n",
            "  inflating: original/512.gexf       \n",
            "  inflating: original/513.gexf       \n",
            "  inflating: original/514.gexf       \n",
            "  inflating: original/515.gexf       \n",
            "  inflating: original/516.gexf       \n",
            "  inflating: original/518.gexf       \n",
            "  inflating: original/519.gexf       \n",
            "  inflating: original/52.gexf        \n",
            "  inflating: original/520.gexf       \n",
            "  inflating: original/521.gexf       \n",
            "  inflating: original/522.gexf       \n",
            "  inflating: original/524.gexf       \n",
            "  inflating: original/525.gexf       \n",
            "  inflating: original/526.gexf       \n",
            "  inflating: original/527.gexf       \n",
            "  inflating: original/528.gexf       \n",
            "  inflating: original/529.gexf       \n",
            "  inflating: original/530.gexf       \n",
            "  inflating: original/531.gexf       \n",
            "  inflating: original/532.gexf       \n",
            "  inflating: original/533.gexf       \n",
            "  inflating: original/535.gexf       \n",
            "  inflating: original/536.gexf       \n",
            "  inflating: original/537.gexf       \n",
            "  inflating: original/538.gexf       \n",
            "  inflating: original/539.gexf       \n",
            "  inflating: original/54.gexf        \n",
            "  inflating: original/540.gexf       \n",
            "  inflating: original/541.gexf       \n",
            "  inflating: original/542.gexf       \n",
            "  inflating: original/543.gexf       \n",
            "  inflating: original/544.gexf       \n",
            "  inflating: original/545.gexf       \n",
            "  inflating: original/546.gexf       \n",
            "  inflating: original/547.gexf       \n",
            "  inflating: original/548.gexf       \n",
            "  inflating: original/549.gexf       \n",
            "  inflating: original/55.gexf        \n",
            "  inflating: original/550.gexf       \n",
            "  inflating: original/551.gexf       \n",
            "  inflating: original/552.gexf       \n",
            "  inflating: original/553.gexf       \n",
            "  inflating: original/554.gexf       \n",
            "  inflating: original/555.gexf       \n",
            "  inflating: original/557.gexf       \n",
            "  inflating: original/558.gexf       \n",
            "  inflating: original/559.gexf       \n",
            "  inflating: original/56.gexf        \n",
            "  inflating: original/560.gexf       \n",
            "  inflating: original/562.gexf       \n",
            "  inflating: original/563.gexf       \n",
            "  inflating: original/564.gexf       \n",
            "  inflating: original/566.gexf       \n",
            "  inflating: original/567.gexf       \n",
            "  inflating: original/569.gexf       \n",
            "  inflating: original/57.gexf        \n",
            "  inflating: original/571.gexf       \n",
            "  inflating: original/572.gexf       \n",
            "  inflating: original/573.gexf       \n",
            "  inflating: original/574.gexf       \n",
            "  inflating: original/575.gexf       \n",
            "  inflating: original/576.gexf       \n",
            "  inflating: original/577.gexf       \n",
            "  inflating: original/579.gexf       \n",
            "  inflating: original/58.gexf        \n",
            "  inflating: original/580.gexf       \n",
            "  inflating: original/581.gexf       \n",
            "  inflating: original/582.gexf       \n",
            "  inflating: original/583.gexf       \n",
            "  inflating: original/584.gexf       \n",
            "  inflating: original/585.gexf       \n",
            "  inflating: original/586.gexf       \n",
            "  inflating: original/587.gexf       \n",
            "  inflating: original/588.gexf       \n",
            "  inflating: original/589.gexf       \n",
            "  inflating: original/59.gexf        \n",
            "  inflating: original/590.gexf       \n",
            "  inflating: original/591.gexf       \n",
            "  inflating: original/593.gexf       \n",
            "  inflating: original/594.gexf       \n",
            "  inflating: original/596.gexf       \n",
            "  inflating: original/597.gexf       \n",
            "  inflating: original/599.gexf       \n",
            "  inflating: original/6.gexf         \n",
            "  inflating: original/600.gexf       \n",
            "  inflating: original/601.gexf       \n",
            "  inflating: original/602.gexf       \n",
            "  inflating: original/604.gexf       \n",
            "  inflating: original/605.gexf       \n",
            "  inflating: original/606.gexf       \n",
            "  inflating: original/607.gexf       \n",
            "  inflating: original/608.gexf       \n",
            "  inflating: original/609.gexf       \n",
            "  inflating: original/61.gexf        \n",
            "  inflating: original/610.gexf       \n",
            "  inflating: original/611.gexf       \n",
            "  inflating: original/612.gexf       \n",
            "  inflating: original/613.gexf       \n",
            "  inflating: original/614.gexf       \n",
            "  inflating: original/615.gexf       \n",
            "  inflating: original/616.gexf       \n",
            "  inflating: original/617.gexf       \n",
            "  inflating: original/618.gexf       \n",
            "  inflating: original/619.gexf       \n",
            "  inflating: original/62.gexf        \n",
            "  inflating: original/620.gexf       \n",
            "  inflating: original/621.gexf       \n",
            "  inflating: original/622.gexf       \n",
            "  inflating: original/623.gexf       \n",
            "  inflating: original/624.gexf       \n",
            "  inflating: original/625.gexf       \n",
            "  inflating: original/627.gexf       \n",
            "  inflating: original/629.gexf       \n",
            "  inflating: original/630.gexf       \n",
            "  inflating: original/631.gexf       \n",
            "  inflating: original/632.gexf       \n",
            "  inflating: original/633.gexf       \n",
            "  inflating: original/634.gexf       \n",
            "  inflating: original/635.gexf       \n",
            "  inflating: original/637.gexf       \n",
            "  inflating: original/638.gexf       \n",
            "  inflating: original/639.gexf       \n",
            "  inflating: original/64.gexf        \n",
            "  inflating: original/641.gexf       \n",
            "  inflating: original/642.gexf       \n",
            "  inflating: original/643.gexf       \n",
            "  inflating: original/644.gexf       \n",
            "  inflating: original/647.gexf       \n",
            "  inflating: original/648.gexf       \n",
            "  inflating: original/649.gexf       \n",
            "  inflating: original/65.gexf        \n",
            "  inflating: original/651.gexf       \n",
            "  inflating: original/652.gexf       \n",
            "  inflating: original/653.gexf       \n",
            "  inflating: original/654.gexf       \n",
            "  inflating: original/656.gexf       \n",
            "  inflating: original/657.gexf       \n",
            "  inflating: original/658.gexf       \n",
            "  inflating: original/66.gexf        \n",
            "  inflating: original/660.gexf       \n",
            "  inflating: original/661.gexf       \n",
            "  inflating: original/662.gexf       \n",
            "  inflating: original/664.gexf       \n",
            "  inflating: original/665.gexf       \n",
            "  inflating: original/666.gexf       \n",
            "  inflating: original/667.gexf       \n",
            "  inflating: original/669.gexf       \n",
            "  inflating: original/67.gexf        \n",
            "  inflating: original/670.gexf       \n",
            "  inflating: original/671.gexf       \n",
            "  inflating: original/672.gexf       \n",
            "  inflating: original/673.gexf       \n",
            "  inflating: original/674.gexf       \n",
            "  inflating: original/676.gexf       \n",
            "  inflating: original/677.gexf       \n",
            "  inflating: original/678.gexf       \n",
            "  inflating: original/679.gexf       \n",
            "  inflating: original/680.gexf       \n",
            "  inflating: original/681.gexf       \n",
            "  inflating: original/682.gexf       \n",
            "  inflating: original/683.gexf       \n",
            "  inflating: original/684.gexf       \n",
            "  inflating: original/685.gexf       \n",
            "  inflating: original/686.gexf       \n",
            "  inflating: original/687.gexf       \n",
            "  inflating: original/688.gexf       \n",
            "  inflating: original/69.gexf        \n",
            "  inflating: original/690.gexf       \n",
            "  inflating: original/691.gexf       \n",
            "  inflating: original/693.gexf       \n",
            "  inflating: original/695.gexf       \n",
            "  inflating: original/696.gexf       \n",
            "  inflating: original/697.gexf       \n",
            "  inflating: original/698.gexf       \n",
            "  inflating: original/699.gexf       \n",
            "  inflating: original/7.gexf         \n",
            "  inflating: original/70.gexf        \n",
            "  inflating: original/700.gexf       \n",
            "  inflating: original/701.gexf       \n",
            "  inflating: original/703.gexf       \n",
            "  inflating: original/705.gexf       \n",
            "  inflating: original/706.gexf       \n",
            "  inflating: original/708.gexf       \n",
            "  inflating: original/709.gexf       \n",
            "  inflating: original/71.gexf        \n",
            "  inflating: original/710.gexf       \n",
            "  inflating: original/711.gexf       \n",
            "  inflating: original/712.gexf       \n",
            "  inflating: original/713.gexf       \n",
            "  inflating: original/714.gexf       \n",
            "  inflating: original/715.gexf       \n",
            "  inflating: original/716.gexf       \n",
            "  inflating: original/717.gexf       \n",
            "  inflating: original/718.gexf       \n",
            "  inflating: original/719.gexf       \n",
            "  inflating: original/72.gexf        \n",
            "  inflating: original/720.gexf       \n",
            "  inflating: original/721.gexf       \n",
            "  inflating: original/722.gexf       \n",
            "  inflating: original/723.gexf       \n",
            "  inflating: original/725.gexf       \n",
            "  inflating: original/726.gexf       \n",
            "  inflating: original/727.gexf       \n",
            "  inflating: original/728.gexf       \n",
            "  inflating: original/729.gexf       \n",
            "  inflating: original/73.gexf        \n",
            "  inflating: original/732.gexf       \n",
            "  inflating: original/733.gexf       \n",
            "  inflating: original/734.gexf       \n",
            "  inflating: original/735.gexf       \n",
            "  inflating: original/736.gexf       \n",
            "  inflating: original/738.gexf       \n",
            "  inflating: original/739.gexf       \n",
            "  inflating: original/74.gexf        \n",
            "  inflating: original/740.gexf       \n",
            "  inflating: original/742.gexf       \n",
            "  inflating: original/743.gexf       \n",
            "  inflating: original/744.gexf       \n",
            "  inflating: original/745.gexf       \n",
            "  inflating: original/746.gexf       \n",
            "  inflating: original/748.gexf       \n",
            "  inflating: original/749.gexf       \n",
            "  inflating: original/75.gexf        \n",
            "  inflating: original/751.gexf       \n",
            "  inflating: original/753.gexf       \n",
            "  inflating: original/754.gexf       \n",
            "  inflating: original/756.gexf       \n",
            "  inflating: original/757.gexf       \n",
            "  inflating: original/758.gexf       \n",
            "  inflating: original/76.gexf        \n",
            "  inflating: original/760.gexf       \n",
            "  inflating: original/761.gexf       \n",
            "  inflating: original/762.gexf       \n",
            "  inflating: original/764.gexf       \n",
            "  inflating: original/769.gexf       \n",
            "  inflating: original/77.gexf        \n",
            "  inflating: original/770.gexf       \n",
            "  inflating: original/771.gexf       \n",
            "  inflating: original/772.gexf       \n",
            "  inflating: original/776.gexf       \n",
            "  inflating: original/777.gexf       \n",
            "  inflating: original/778.gexf       \n",
            "  inflating: original/779.gexf       \n",
            "  inflating: original/78.gexf        \n",
            "  inflating: original/780.gexf       \n",
            "  inflating: original/782.gexf       \n",
            "  inflating: original/783.gexf       \n",
            "  inflating: original/784.gexf       \n",
            "  inflating: original/785.gexf       \n",
            "  inflating: original/788.gexf       \n",
            "  inflating: original/789.gexf       \n",
            "  inflating: original/79.gexf        \n",
            "  inflating: original/790.gexf       \n",
            "  inflating: original/791.gexf       \n",
            "  inflating: original/792.gexf       \n",
            "  inflating: original/793.gexf       \n",
            "  inflating: original/794.gexf       \n",
            "  inflating: original/795.gexf       \n",
            "  inflating: original/797.gexf       \n",
            "  inflating: original/798.gexf       \n",
            "  inflating: original/80.gexf        \n",
            "  inflating: original/800.gexf       \n",
            "  inflating: original/801.gexf       \n",
            "  inflating: original/802.gexf       \n",
            "  inflating: original/803.gexf       \n",
            "  inflating: original/804.gexf       \n",
            "  inflating: original/805.gexf       \n",
            "  inflating: original/806.gexf       \n",
            "  inflating: original/807.gexf       \n",
            "  inflating: original/808.gexf       \n",
            "  inflating: original/809.gexf       \n",
            "  inflating: original/81.gexf        \n",
            "  inflating: original/810.gexf       \n",
            "  inflating: original/811.gexf       \n",
            "  inflating: original/812.gexf       \n",
            "  inflating: original/813.gexf       \n",
            "  inflating: original/816.gexf       \n",
            "  inflating: original/817.gexf       \n",
            "  inflating: original/818.gexf       \n",
            "  inflating: original/82.gexf        \n",
            "  inflating: original/820.gexf       \n",
            "  inflating: original/822.gexf       \n",
            "  inflating: original/823.gexf       \n",
            "  inflating: original/824.gexf       \n",
            "  inflating: original/826.gexf       \n",
            "  inflating: original/827.gexf       \n",
            "  inflating: original/828.gexf       \n",
            "  inflating: original/829.gexf       \n",
            "  inflating: original/83.gexf        \n",
            "  inflating: original/830.gexf       \n",
            "  inflating: original/831.gexf       \n",
            "  inflating: original/832.gexf       \n",
            "  inflating: original/833.gexf       \n",
            "  inflating: original/834.gexf       \n",
            "  inflating: original/835.gexf       \n",
            "  inflating: original/836.gexf       \n",
            "  inflating: original/837.gexf       \n",
            "  inflating: original/838.gexf       \n",
            "  inflating: original/839.gexf       \n",
            "  inflating: original/84.gexf        \n",
            "  inflating: original/840.gexf       \n",
            "  inflating: original/841.gexf       \n",
            "  inflating: original/842.gexf       \n",
            "  inflating: original/844.gexf       \n",
            "  inflating: original/845.gexf       \n",
            "  inflating: original/846.gexf       \n",
            "  inflating: original/847.gexf       \n",
            "  inflating: original/849.gexf       \n",
            "  inflating: original/85.gexf        \n",
            "  inflating: original/850.gexf       \n",
            "  inflating: original/852.gexf       \n",
            "  inflating: original/853.gexf       \n",
            "  inflating: original/854.gexf       \n",
            "  inflating: original/855.gexf       \n",
            "  inflating: original/856.gexf       \n",
            "  inflating: original/857.gexf       \n",
            "  inflating: original/858.gexf       \n",
            "  inflating: original/859.gexf       \n",
            "  inflating: original/860.gexf       \n",
            "  inflating: original/861.gexf       \n",
            "  inflating: original/862.gexf       \n",
            "  inflating: original/864.gexf       \n",
            "  inflating: original/866.gexf       \n",
            "  inflating: original/867.gexf       \n",
            "  inflating: original/868.gexf       \n",
            "  inflating: original/87.gexf        \n",
            "  inflating: original/870.gexf       \n",
            "  inflating: original/871.gexf       \n",
            "  inflating: original/872.gexf       \n",
            "  inflating: original/873.gexf       \n",
            "  inflating: original/876.gexf       \n",
            "  inflating: original/878.gexf       \n",
            "  inflating: original/88.gexf        \n",
            "  inflating: original/880.gexf       \n",
            "  inflating: original/881.gexf       \n",
            "  inflating: original/882.gexf       \n",
            "  inflating: original/883.gexf       \n",
            "  inflating: original/884.gexf       \n",
            "  inflating: original/885.gexf       \n",
            "  inflating: original/886.gexf       \n",
            "  inflating: original/887.gexf       \n",
            "  inflating: original/888.gexf       \n",
            "  inflating: original/89.gexf        \n",
            "  inflating: original/890.gexf       \n",
            "  inflating: original/891.gexf       \n",
            "  inflating: original/892.gexf       \n",
            "  inflating: original/894.gexf       \n",
            "  inflating: original/895.gexf       \n",
            "  inflating: original/897.gexf       \n",
            "  inflating: original/899.gexf       \n",
            "  inflating: original/9.gexf         \n",
            "  inflating: original/90.gexf        \n",
            "  inflating: original/900.gexf       \n",
            "  inflating: original/901.gexf       \n",
            "  inflating: original/902.gexf       \n",
            "  inflating: original/903.gexf       \n",
            "  inflating: original/904.gexf       \n",
            "  inflating: original/905.gexf       \n",
            "  inflating: original/906.gexf       \n",
            "  inflating: original/907.gexf       \n",
            "  inflating: original/909.gexf       \n",
            "  inflating: original/91.gexf        \n",
            "  inflating: original/910.gexf       \n",
            "  inflating: original/912.gexf       \n",
            "  inflating: original/913.gexf       \n",
            "  inflating: original/914.gexf       \n",
            "  inflating: original/915.gexf       \n",
            "  inflating: original/916.gexf       \n",
            "  inflating: original/917.gexf       \n",
            "  inflating: original/919.gexf       \n",
            "  inflating: original/92.gexf        \n",
            "  inflating: original/921.gexf       \n",
            "  inflating: original/922.gexf       \n",
            "  inflating: original/923.gexf       \n",
            "  inflating: original/924.gexf       \n",
            "  inflating: original/925.gexf       \n",
            "  inflating: original/926.gexf       \n",
            "  inflating: original/927.gexf       \n",
            "  inflating: original/929.gexf       \n",
            "  inflating: original/93.gexf        \n",
            "  inflating: original/930.gexf       \n",
            "  inflating: original/931.gexf       \n",
            "  inflating: original/932.gexf       \n",
            "  inflating: original/933.gexf       \n",
            "  inflating: original/934.gexf       \n",
            "  inflating: original/935.gexf       \n",
            "  inflating: original/936.gexf       \n",
            "  inflating: original/937.gexf       \n",
            "  inflating: original/939.gexf       \n",
            "  inflating: original/94.gexf        \n",
            "  inflating: original/940.gexf       \n",
            "  inflating: original/941.gexf       \n",
            "  inflating: original/942.gexf       \n",
            "  inflating: original/943.gexf       \n",
            "  inflating: original/944.gexf       \n",
            "  inflating: original/945.gexf       \n",
            "  inflating: original/946.gexf       \n",
            "  inflating: original/947.gexf       \n",
            "  inflating: original/948.gexf       \n",
            "  inflating: original/949.gexf       \n",
            "  inflating: original/950.gexf       \n",
            "  inflating: original/952.gexf       \n",
            "  inflating: original/954.gexf       \n",
            "  inflating: original/955.gexf       \n",
            "  inflating: original/956.gexf       \n",
            "  inflating: original/957.gexf       \n",
            "  inflating: original/958.gexf       \n",
            "  inflating: original/96.gexf        \n",
            "  inflating: original/961.gexf       \n",
            "  inflating: original/962.gexf       \n",
            "  inflating: original/963.gexf       \n",
            "  inflating: original/964.gexf       \n",
            "  inflating: original/965.gexf       \n",
            "  inflating: original/966.gexf       \n",
            "  inflating: original/967.gexf       \n",
            "  inflating: original/968.gexf       \n",
            "  inflating: original/969.gexf       \n",
            "  inflating: original/97.gexf        \n",
            "  inflating: original/970.gexf       \n",
            "  inflating: original/971.gexf       \n",
            "  inflating: original/972.gexf       \n",
            "  inflating: original/973.gexf       \n",
            "  inflating: original/974.gexf       \n",
            "  inflating: original/975.gexf       \n",
            "  inflating: original/976.gexf       \n",
            "  inflating: original/977.gexf       \n",
            "  inflating: original/978.gexf       \n",
            "  inflating: original/979.gexf       \n",
            "  inflating: original/981.gexf       \n",
            "  inflating: original/983.gexf       \n",
            "  inflating: original/986.gexf       \n",
            "  inflating: original/987.gexf       \n",
            "  inflating: original/988.gexf       \n",
            "  inflating: original/989.gexf       \n",
            "  inflating: original/99.gexf        \n",
            "  inflating: original/990.gexf       \n",
            "  inflating: original/993.gexf       \n",
            "  inflating: original/994.gexf       \n",
            "  inflating: original/995.gexf       \n",
            "  inflating: original/996.gexf       \n",
            "  inflating: original/997.gexf       \n",
            "  inflating: original/998.gexf       \n",
            "  inflating: original/999.gexf       \n",
            "   creating: test/\n",
            "  inflating: test/100.gexf           \n",
            "  inflating: test/1000.gexf          \n",
            "  inflating: test/1003.gexf          \n",
            "  inflating: test/1008.gexf          \n",
            "  inflating: test/1011.gexf          \n",
            "  inflating: test/1014.gexf          \n",
            "  inflating: test/102.gexf           \n",
            "  inflating: test/1020.gexf          \n",
            "  inflating: test/1026.gexf          \n",
            "  inflating: test/1032.gexf          \n",
            "  inflating: test/1035.gexf          \n",
            "  inflating: test/1036.gexf          \n",
            "  inflating: test/1040.gexf          \n",
            "  inflating: test/1051.gexf          \n",
            "  inflating: test/1061.gexf          \n",
            "  inflating: test/1064.gexf          \n",
            "  inflating: test/1069.gexf          \n",
            "  inflating: test/1070.gexf          \n",
            "  inflating: test/1071.gexf          \n",
            "  inflating: test/1078.gexf          \n",
            "  inflating: test/1082.gexf          \n",
            "  inflating: test/1086.gexf          \n",
            "  inflating: test/1090.gexf          \n",
            "  inflating: test/1092.gexf          \n",
            "  inflating: test/1096.gexf          \n",
            "  inflating: test/11.gexf            \n",
            "  inflating: test/1100.gexf          \n",
            "  inflating: test/1103.gexf          \n",
            "  inflating: test/1107.gexf          \n",
            "  inflating: test/111.gexf           \n",
            "  inflating: test/1113.gexf          \n",
            "  inflating: test/1116.gexf          \n",
            "  inflating: test/1120.gexf          \n",
            "  inflating: test/1122.gexf          \n",
            "  inflating: test/1124.gexf          \n",
            "  inflating: test/1125.gexf          \n",
            "  inflating: test/1128.gexf          \n",
            "  inflating: test/1135.gexf          \n",
            "  inflating: test/1147.gexf          \n",
            "  inflating: test/1157.gexf          \n",
            "  inflating: test/116.gexf           \n",
            "  inflating: test/1164.gexf          \n",
            "  inflating: test/1165.gexf          \n",
            "  inflating: test/1168.gexf          \n",
            "  inflating: test/1170.gexf          \n",
            "  inflating: test/1173.gexf          \n",
            "  inflating: test/1177.gexf          \n",
            "  inflating: test/118.gexf           \n",
            "  inflating: test/1181.gexf          \n",
            "  inflating: test/1185.gexf          \n",
            "  inflating: test/1186.gexf          \n",
            "  inflating: test/1190.gexf          \n",
            "  inflating: test/1193.gexf          \n",
            "  inflating: test/1201.gexf          \n",
            "  inflating: test/1219.gexf          \n",
            "  inflating: test/1225.gexf          \n",
            "  inflating: test/1236.gexf          \n",
            "  inflating: test/1238.gexf          \n",
            "  inflating: test/1243.gexf          \n",
            "  inflating: test/1247.gexf          \n",
            "  inflating: test/1249.gexf          \n",
            "  inflating: test/1260.gexf          \n",
            "  inflating: test/1266.gexf          \n",
            "  inflating: test/1269.gexf          \n",
            "  inflating: test/127.gexf           \n",
            "  inflating: test/1276.gexf          \n",
            "  inflating: test/128.gexf           \n",
            "  inflating: test/1286.gexf          \n",
            "  inflating: test/1291.gexf          \n",
            "  inflating: test/1292.gexf          \n",
            "  inflating: test/1300.gexf          \n",
            "  inflating: test/1305.gexf          \n",
            "  inflating: test/1308.gexf          \n",
            "  inflating: test/131.gexf           \n",
            "  inflating: test/1310.gexf          \n",
            "  inflating: test/1311.gexf          \n",
            "  inflating: test/1315.gexf          \n",
            "  inflating: test/1324.gexf          \n",
            "  inflating: test/1325.gexf          \n",
            "  inflating: test/1330.gexf          \n",
            "  inflating: test/1343.gexf          \n",
            "  inflating: test/1345.gexf          \n",
            "  inflating: test/1361.gexf          \n",
            "  inflating: test/1362.gexf          \n",
            "  inflating: test/1363.gexf          \n",
            "  inflating: test/137.gexf           \n",
            "  inflating: test/1371.gexf          \n",
            "  inflating: test/1375.gexf          \n",
            "  inflating: test/1376.gexf          \n",
            "  inflating: test/1379.gexf          \n",
            "  inflating: test/138.gexf           \n",
            "  inflating: test/1381.gexf          \n",
            "  inflating: test/1383.gexf          \n",
            "  inflating: test/1387.gexf          \n",
            "  inflating: test/1394.gexf          \n",
            "  inflating: test/1397.gexf          \n",
            "  inflating: test/14.gexf            \n",
            "  inflating: test/1400.gexf          \n",
            "  inflating: test/1402.gexf          \n",
            "  inflating: test/1405.gexf          \n",
            "  inflating: test/1407.gexf          \n",
            "  inflating: test/1410.gexf          \n",
            "  inflating: test/1413.gexf          \n",
            "  inflating: test/1414.gexf          \n",
            "  inflating: test/1417.gexf          \n",
            "  inflating: test/142.gexf           \n",
            "  inflating: test/1423.gexf          \n",
            "  inflating: test/1424.gexf          \n",
            "  inflating: test/1447.gexf          \n",
            "  inflating: test/145.gexf           \n",
            "  inflating: test/1465.gexf          \n",
            "  inflating: test/1466.gexf          \n",
            "  inflating: test/1475.gexf          \n",
            "  inflating: test/1482.gexf          \n",
            "  inflating: test/149.gexf           \n",
            "  inflating: test/1490.gexf          \n",
            "  inflating: test/1491.gexf          \n",
            "  inflating: test/152.gexf           \n",
            "  inflating: test/155.gexf           \n",
            "  inflating: test/173.gexf           \n",
            "  inflating: test/174.gexf           \n",
            "  inflating: test/180.gexf           \n",
            "  inflating: test/182.gexf           \n",
            "  inflating: test/186.gexf           \n",
            "  inflating: test/187.gexf           \n",
            "  inflating: test/205.gexf           \n",
            "  inflating: test/207.gexf           \n",
            "  inflating: test/215.gexf           \n",
            "  inflating: test/226.gexf           \n",
            "  inflating: test/228.gexf           \n",
            "  inflating: test/237.gexf           \n",
            "  inflating: test/238.gexf           \n",
            "  inflating: test/239.gexf           \n",
            "  inflating: test/247.gexf           \n",
            "  inflating: test/257.gexf           \n",
            "  inflating: test/259.gexf           \n",
            "  inflating: test/270.gexf           \n",
            "  inflating: test/278.gexf           \n",
            "  inflating: test/290.gexf           \n",
            "  inflating: test/292.gexf           \n",
            "  inflating: test/302.gexf           \n",
            "  inflating: test/320.gexf           \n",
            "  inflating: test/324.gexf           \n",
            "  inflating: test/326.gexf           \n",
            "  inflating: test/33.gexf            \n",
            "  inflating: test/336.gexf           \n",
            "  inflating: test/340.gexf           \n",
            "  inflating: test/341.gexf           \n",
            "  inflating: test/344.gexf           \n",
            "  inflating: test/346.gexf           \n",
            "  inflating: test/35.gexf            \n",
            "  inflating: test/350.gexf           \n",
            "  inflating: test/352.gexf           \n",
            "  inflating: test/353.gexf           \n",
            "  inflating: test/354.gexf           \n",
            "  inflating: test/359.gexf           \n",
            "  inflating: test/36.gexf            \n",
            "  inflating: test/363.gexf           \n",
            "  inflating: test/367.gexf           \n",
            "  inflating: test/378.gexf           \n",
            "  inflating: test/38.gexf            \n",
            "  inflating: test/380.gexf           \n",
            "  inflating: test/382.gexf           \n",
            "  inflating: test/384.gexf           \n",
            "  inflating: test/391.gexf           \n",
            "  inflating: test/393.gexf           \n",
            "  inflating: test/397.gexf           \n",
            "  inflating: test/400.gexf           \n",
            "  inflating: test/401.gexf           \n",
            "  inflating: test/404.gexf           \n",
            "  inflating: test/405.gexf           \n",
            "  inflating: test/406.gexf           \n",
            "  inflating: test/413.gexf           \n",
            "  inflating: test/432.gexf           \n",
            "  inflating: test/434.gexf           \n",
            "  inflating: test/435.gexf           \n",
            "  inflating: test/436.gexf           \n",
            "  inflating: test/437.gexf           \n",
            "  inflating: test/440.gexf           \n",
            "  inflating: test/441.gexf           \n",
            "  inflating: test/442.gexf           \n",
            "  inflating: test/445.gexf           \n",
            "  inflating: test/446.gexf           \n",
            "  inflating: test/449.gexf           \n",
            "  inflating: test/450.gexf           \n",
            "  inflating: test/452.gexf           \n",
            "  inflating: test/453.gexf           \n",
            "  inflating: test/455.gexf           \n",
            "  inflating: test/463.gexf           \n",
            "  inflating: test/47.gexf            \n",
            "  inflating: test/471.gexf           \n",
            "  inflating: test/473.gexf           \n",
            "  inflating: test/474.gexf           \n",
            "  inflating: test/476.gexf           \n",
            "  inflating: test/477.gexf           \n",
            "  inflating: test/479.gexf           \n",
            "  inflating: test/480.gexf           \n",
            "  inflating: test/495.gexf           \n",
            "  inflating: test/497.gexf           \n",
            "  inflating: test/50.gexf            \n",
            "  inflating: test/502.gexf           \n",
            "  inflating: test/508.gexf           \n",
            "  inflating: test/509.gexf           \n",
            "  inflating: test/517.gexf           \n",
            "  inflating: test/523.gexf           \n",
            "  inflating: test/53.gexf            \n",
            "  inflating: test/534.gexf           \n",
            "  inflating: test/556.gexf           \n",
            "  inflating: test/561.gexf           \n",
            "  inflating: test/565.gexf           \n",
            "  inflating: test/568.gexf           \n",
            "  inflating: test/570.gexf           \n",
            "  inflating: test/578.gexf           \n",
            "  inflating: test/592.gexf           \n",
            "  inflating: test/595.gexf           \n",
            "  inflating: test/598.gexf           \n",
            "  inflating: test/60.gexf            \n",
            "  inflating: test/603.gexf           \n",
            "  inflating: test/626.gexf           \n",
            "  inflating: test/628.gexf           \n",
            "  inflating: test/63.gexf            \n",
            "  inflating: test/636.gexf           \n",
            "  inflating: test/640.gexf           \n",
            "  inflating: test/645.gexf           \n",
            "  inflating: test/646.gexf           \n",
            "  inflating: test/650.gexf           \n",
            "  inflating: test/655.gexf           \n",
            "  inflating: test/659.gexf           \n",
            "  inflating: test/663.gexf           \n",
            "  inflating: test/668.gexf           \n",
            "  inflating: test/675.gexf           \n",
            "  inflating: test/68.gexf            \n",
            "  inflating: test/689.gexf           \n",
            "  inflating: test/692.gexf           \n",
            "  inflating: test/694.gexf           \n",
            "  inflating: test/702.gexf           \n",
            "  inflating: test/704.gexf           \n",
            "  inflating: test/707.gexf           \n",
            "  inflating: test/724.gexf           \n",
            "  inflating: test/730.gexf           \n",
            "  inflating: test/731.gexf           \n",
            "  inflating: test/737.gexf           \n",
            "  inflating: test/741.gexf           \n",
            "  inflating: test/747.gexf           \n",
            "  inflating: test/750.gexf           \n",
            "  inflating: test/752.gexf           \n",
            "  inflating: test/755.gexf           \n",
            "  inflating: test/759.gexf           \n",
            "  inflating: test/763.gexf           \n",
            "  inflating: test/765.gexf           \n",
            "  inflating: test/766.gexf           \n",
            "  inflating: test/767.gexf           \n",
            "  inflating: test/768.gexf           \n",
            "  inflating: test/773.gexf           \n",
            "  inflating: test/774.gexf           \n",
            "  inflating: test/775.gexf           \n",
            "  inflating: test/781.gexf           \n",
            "  inflating: test/786.gexf           \n",
            "  inflating: test/787.gexf           \n",
            "  inflating: test/796.gexf           \n",
            "  inflating: test/799.gexf           \n",
            "  inflating: test/8.gexf             \n",
            "  inflating: test/814.gexf           \n",
            "  inflating: test/815.gexf           \n",
            "  inflating: test/819.gexf           \n",
            "  inflating: test/821.gexf           \n",
            "  inflating: test/825.gexf           \n",
            "  inflating: test/843.gexf           \n",
            "  inflating: test/848.gexf           \n",
            "  inflating: test/851.gexf           \n",
            "  inflating: test/86.gexf            \n",
            "  inflating: test/863.gexf           \n",
            "  inflating: test/865.gexf           \n",
            "  inflating: test/869.gexf           \n",
            "  inflating: test/874.gexf           \n",
            "  inflating: test/875.gexf           \n",
            "  inflating: test/877.gexf           \n",
            "  inflating: test/879.gexf           \n",
            "  inflating: test/889.gexf           \n",
            "  inflating: test/893.gexf           \n",
            "  inflating: test/896.gexf           \n",
            "  inflating: test/898.gexf           \n",
            "  inflating: test/908.gexf           \n",
            "  inflating: test/911.gexf           \n",
            "  inflating: test/918.gexf           \n",
            "  inflating: test/920.gexf           \n",
            "  inflating: test/928.gexf           \n",
            "  inflating: test/938.gexf           \n",
            "  inflating: test/95.gexf            \n",
            "  inflating: test/951.gexf           \n",
            "  inflating: test/953.gexf           \n",
            "  inflating: test/959.gexf           \n",
            "  inflating: test/960.gexf           \n",
            "  inflating: test/98.gexf            \n",
            "  inflating: test/980.gexf           \n",
            "  inflating: test/982.gexf           \n",
            "  inflating: test/984.gexf           \n",
            "  inflating: test/985.gexf           \n",
            "  inflating: test/991.gexf           \n",
            "  inflating: test/992.gexf           \n",
            "   creating: test_gen/\n",
            "  inflating: test_gen/1000_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1003_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1008_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/100_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1011_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1014_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1020_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1026_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/102_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1032_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1035_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1036_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1040_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1051_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1061_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1064_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1069_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1070_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1071_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1078_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1082_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1086_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1090_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1092_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1096_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1100_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1103_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1107_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1113_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1116_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/111_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1120_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1122_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1124_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1125_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1128_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1135_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1147_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1157_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1164_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1165_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1168_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/116_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1170_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1173_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1177_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1181_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1185_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1186_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/118_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1190_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1193_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/11_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1201_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1219_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1225_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1236_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1238_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1243_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1247_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1249_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1260_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1266_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1269_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1276_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/127_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1286_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/128_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1291_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1292_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1300_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1305_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1308_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1310_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1311_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1315_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/131_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1324_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1325_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1330_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1343_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1345_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1361_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1362_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1363_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1371_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1375_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1376_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1379_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/137_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1381_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1383_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1387_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/138_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1394_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1397_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1400_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1402_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1405_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1407_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1410_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1413_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1414_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1417_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1423_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/1424_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/142_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1447_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/145_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/1465_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1466_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1475_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/1482_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1490_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/1491_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/149_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/14_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/152_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/155_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/173_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/174_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/180_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/182_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/186_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/187_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/205_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/207_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/215_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/226_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/228_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/237_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/238_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/239_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/247_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/257_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/259_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/270_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/278_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/290_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/292_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/302_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/320_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/324_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/326_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/336_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/33_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/340_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/341_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/344_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/346_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/350_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/352_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/353_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/354_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/359_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/35_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/363_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/367_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/36_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/378_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/380_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/382_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/384_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/38_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/391_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/393_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/397_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/400_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/401_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/404_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/405_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/406_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/413_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/432_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/434_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/435_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/436_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/437_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/440_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/441_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/442_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/445_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/446_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/449_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/450_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/452_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/453_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/455_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/463_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/471_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/473_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/474_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/476_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/477_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/479_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/47_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/480_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/495_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/497_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/502_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/508_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/509_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/50_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/517_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/523_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/534_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/53_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/556_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/561_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/565_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/568_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/570_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/578_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/592_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/595_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/598_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/603_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/60_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/626_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/628_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/636_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/63_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/640_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/645_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/646_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/650_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/655_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/659_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/663_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/668_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/675_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/689_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/68_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/692_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/694_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/702_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/704_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/707_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/724_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/730_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/731_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/737_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/741_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/747_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/750_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/752_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/755_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/759_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/763_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/765_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/766_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/767_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/768_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/773_NR_0_NID_1_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/774_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/775_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/781_NR_0_NID_1_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/786_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/787_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/796_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/799_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/814_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/815_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/819_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/821_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/825_NR_0_NID_3_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/843_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/848_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/851_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/863_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/865_NR_0_NID_1_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/869_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/86_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/874_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/875_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/877_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/879_NR_0_NID_0_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/889_NR_0_NID_0_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/893_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/896_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/898_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/8_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/908_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/911_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/918_NR_0_NID_2_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/920_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/928_NR_0_NID_0_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/938_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/951_NR_0_NID_1_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/953_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/959_NR_0_NID_2_ER_0_EID_0.gexf  \n",
            "  inflating: test_gen/95_NR_0_NID_2_ER_0_EID_2.gexf  \n",
            "  inflating: test_gen/960_NR_0_NID_3_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/980_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/982_NR_0_NID_2_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/984_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/985_NR_0_NID_3_ER_0_EID_3.gexf  \n",
            "  inflating: test_gen/98_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/991_NR_0_NID_0_ER_0_EID_1.gexf  \n",
            "  inflating: test_gen/992_NR_0_NID_3_ER_0_EID_0.gexf  \n",
            "  inflating: testing_pairs - 副本.csv  \n",
            "  inflating: testing_pairs.csv       \n",
            "  inflating: training_pairs.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = \"IMDB\"\n",
        "ORI_DIR = \"/content/original\"\n",
        "GEN_DIR =\"/content/generated\"\n",
        "TEST_DIR = \"/content/test\"\n",
        "TEST_GEN_DIR = \"/content/test_gen\"\n",
        "DATASET_FOLDER = \"/content\""
      ],
      "metadata": {
        "id": "7YW9POyVAmNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_csv = pd.DataFrame(test_data, columns=['G1', 'G2', 'gt_ged']).to_csv(DATASET_FOLDER + \"/testing_pairs.csv\",\n",
        "#                                                                           index=False)\n",
        "def load_pairs():\n",
        "    train_pairs = []\n",
        "    train_csv = pd.read_csv(DATASET_FOLDER+\"/training_pairs.csv\")\n",
        "    for index, row in train_csv.iterrows():\n",
        "        file1 = row['G1']\n",
        "        file2 = row['G2']\n",
        "        ged =ast.literal_eval(row['GED'])\n",
        "        new_ged = [ged[1],ged[3]]\n",
        "        gt_ged = row['gt_ged']\n",
        "        graph1 = nx.read_gexf(path=ORI_DIR + '/' + file1)\n",
        "        graph2 = nx.read_gexf(path=GEN_DIR + '/' + file2)\n",
        "        train_pairs.append({\"graph_pair\": [graph1, graph2], \"ged\": new_ged, \"gt_ged\":gt_ged})\n",
        "\n",
        "\n",
        "    test_pairs = []\n",
        "    test_csv = pd.read_csv(DATASET_FOLDER+\"/testing_pairs.csv\")\n",
        "    for index, row in test_csv.iterrows():\n",
        "        file1 = row['G1']\n",
        "        file2 = row['G2']\n",
        "        gt_ged = row['gt_ged']\n",
        "        if gt_ged<=10:\n",
        "          graph1 = nx.read_gexf(path=TEST_DIR + '/' + file1)\n",
        "          graph2 = nx.read_gexf(path=TEST_DIR + '/' + file2)\n",
        "          test_pairs.append({\"graph_pair\": [graph1, graph2], \"gt_ged\": gt_ged})\n",
        "        else:\n",
        "          continue\n",
        "        \n",
        "    return train_pairs, test_pairs\n",
        "train_pairs, test_pairs = load_pairs()\n",
        "print(len(train_pairs))\n",
        "print(train_pairs[0])\n",
        "print(len(test_pairs))\n",
        "print(test_pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8TVFStA5p0",
        "outputId": "f5242abd-31eb-4009-9096-a9b28148e06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n",
            "{'graph_pair': [<networkx.classes.graph.Graph object at 0x7fc87fb8d690>, <networkx.classes.graph.Graph object at 0x7fc87fb6c090>], 'ged': [5, 3], 'gt_ged': 8}\n",
            "42\n",
            "{'graph_pair': [<networkx.classes.graph.Graph object at 0x7fc87667e850>, <networkx.classes.graph.Graph object at 0x7fc8765c6210>], 'gt_ged': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFileInfo(filename):\n",
        "    # if test is False:\n",
        "    #     g = nx.read_gexf(path=\"./dataset/\"+datasetName+ + filename)\n",
        "    # else:\n",
        "    # draw(g)\n",
        "    reg = re.sub(\".*NR_(?P<nr>\\d+)_NID_(?P<nid>\\d+)_ER_(?P<er>\\d+)_EID_(?P<eid>\\d+).gexf\", \"\\g<eid>\", filename)\n",
        "    ori = re.sub(\"(?P<t>.+?)_.*\", \"\\g<t>\", filename)\n",
        "    nr = int(re.sub(\".*NR_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    nid = int(re.sub(\".*NID_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    er = int(re.sub(\".*ER_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    eid = int(re.sub(\".*EID_(?P<t>.+?).gexf\", \"\\g<t>\", filename))\n",
        "    gev = nr + nid + er + eid\n",
        "    # return [ori+'.gexf',str(nr)+str(nid)+str(er)+str(eid)]\n",
        "    return [ori + '.gexf', [nr, nid, er, eid]]\n",
        "    # print('ori',ori, 'nr',nr, 'nid',nid, 'er',er, 'eid',eid,'gev',gev)\n",
        "\n",
        "\n",
        "ori, ged = getFileInfo(\"4_NR_0_NID_4_ER_2_EID_5.gexf\")\n",
        "print(ori, ged)\n",
        "print(sum(ged))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVCp6S65A-7u",
        "outputId": "2e0352aa-d1a3-4ebc-b671-11f36fb774bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.gexf [0, 4, 2, 5]\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Model"
      ],
      "metadata": {
        "id": "ppBMYQ7QBEFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if(graph1_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if(graph1_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if(graph2_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if(graph2_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)# default: sum\n",
        "      graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "      graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "      graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "\n",
        "\n",
        "      scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      scores_in = torch.t(scores_in)\n",
        "\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_in, score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Baseline Model(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-i6Lre4sBIMt",
        "outputId": "5f392b7d-dcbf-4601-e884-4ef444f5c35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.11018319427967072\n",
            "Iteration 1 loss:  0.09984652698040009\n",
            "Iteration 2 loss:  0.08722016215324402\n",
            "Iteration 3 loss:  0.09221681207418442\n",
            "Iteration 4 loss:  0.0782439112663269\n",
            "Iteration 5 loss:  0.08341006189584732\n",
            "Iteration 6 loss:  0.07572915405035019\n",
            "Iteration 7 loss:  0.07510058581829071\n",
            "Iteration 8 loss:  0.07164959609508514\n",
            "Iteration 9 loss:  0.05708879232406616\n",
            "Iteration 10 loss:  0.06109593063592911\n",
            "Iteration 11 loss:  0.057538386434316635\n",
            "Iteration 12 loss:  0.05602240934967995\n",
            "Iteration 13 loss:  0.05730471387505531\n",
            "Iteration 14 loss:  0.05501822754740715\n",
            "Iteration 15 loss:  0.05407807230949402\n",
            "Iteration 16 loss:  0.049935631453990936\n",
            "Iteration 17 loss:  0.05244942009449005\n",
            "Iteration 18 loss:  0.04849521443247795\n",
            "Iteration 19 loss:  0.04325392345587412\n",
            "Iteration 20 loss:  0.0501726008951664\n",
            "Iteration 21 loss:  0.04958074912428856\n",
            "Iteration 22 loss:  0.04340299591422081\n",
            "Iteration 23 loss:  0.04275815188884735\n",
            "Iteration 24 loss:  0.04458823427557945\n",
            "Iteration 25 loss:  0.04363039880990982\n",
            "Iteration 26 loss:  0.03925411403179169\n",
            "Iteration 27 loss:  0.04130972549319267\n",
            "Iteration 28 loss:  0.041201401501894\n",
            "Iteration 29 loss:  0.039954873422781624\n",
            "Iteration 30 loss:  0.037431005388498306\n",
            "Iteration 31 loss:  0.03520538657903671\n",
            "Iteration 32 loss:  0.03657891973853111\n",
            "Iteration 33 loss:  0.03682937100529671\n",
            "Iteration 34 loss:  0.04118047654628754\n",
            "Iteration 35 loss:  0.0328713059425354\n",
            "Iteration 36 loss:  0.037773482501506805\n",
            "Iteration 37 loss:  0.03143061324954033\n",
            "Iteration 38 loss:  0.03672845661640167\n",
            "Iteration 39 loss:  0.04030253738164902\n",
            "Iteration 40 loss:  0.034900687634944916\n",
            "Iteration 41 loss:  0.037320543080568314\n",
            "Iteration 42 loss:  0.028641626238822937\n",
            "Iteration 43 loss:  0.032335128635168076\n",
            "Iteration 44 loss:  0.03283829241991043\n",
            "Iteration 45 loss:  0.033404987305402756\n",
            "Iteration 46 loss:  0.027016466483473778\n",
            "Iteration 47 loss:  0.02859628200531006\n",
            "Iteration 48 loss:  0.029986107721924782\n",
            "Iteration 49 loss:  0.024754509329795837\n",
            "Iteration 50 loss:  0.029302928596735\n",
            "Iteration 51 loss:  0.027324918657541275\n",
            "Iteration 52 loss:  0.02746063470840454\n",
            "Iteration 53 loss:  0.022442840039730072\n",
            "Iteration 54 loss:  0.027357513085007668\n",
            "Iteration 55 loss:  0.031196806579828262\n",
            "Iteration 56 loss:  0.031717799603939056\n",
            "Iteration 57 loss:  0.023854540660977364\n",
            "Iteration 58 loss:  0.02373957820236683\n",
            "Iteration 59 loss:  0.028469229737917583\n",
            "Iteration 60 loss:  0.022803744301199913\n",
            "Iteration 61 loss:  0.025285813957452774\n",
            "Iteration 62 loss:  0.024794915691018105\n",
            "Iteration 63 loss:  0.02538842149078846\n",
            "Iteration 64 loss:  0.023468520492315292\n",
            "Iteration 65 loss:  0.02279755286872387\n",
            "Iteration 66 loss:  0.02034880593419075\n",
            "Iteration 67 loss:  0.020802054554224014\n",
            "Iteration 68 loss:  0.02141379751265049\n",
            "Iteration 69 loss:  0.024276743332544964\n",
            "Iteration 70 loss:  0.022178225219249725\n",
            "Iteration 71 loss:  0.021491048857569695\n",
            "Iteration 72 loss:  0.01831567846238613\n",
            "Iteration 73 loss:  0.018911439925432205\n",
            "Iteration 74 loss:  0.016423627734184265\n",
            "Iteration 75 loss:  0.022615471854805946\n",
            "Iteration 76 loss:  0.01628338359296322\n",
            "Iteration 77 loss:  0.019159678369760513\n",
            "Iteration 78 loss:  0.018069803714752197\n",
            "Iteration 79 loss:  0.027730395396550495\n",
            "Iteration 80 loss:  0.013410570099949837\n",
            "Iteration 81 loss:  0.018797539174556732\n",
            "Iteration 82 loss:  0.017255593091249466\n",
            "Iteration 83 loss:  0.019255641847848892\n",
            "Iteration 84 loss:  0.017396889626979828\n",
            "Iteration 85 loss:  0.020057514309883118\n",
            "Iteration 86 loss:  0.017552312463521957\n",
            "Iteration 87 loss:  0.016050448641180992\n",
            "Iteration 88 loss:  0.01691492833197117\n",
            "Iteration 89 loss:  0.01324655239780744\n",
            "Iteration 90 loss:  0.013254365883767605\n",
            "Iteration 91 loss:  0.016480881720781326\n",
            "Iteration 92 loss:  0.014776941388845444\n",
            "Iteration 93 loss:  0.015046990476548672\n",
            "Iteration 94 loss:  0.018092170357704163\n",
            "Iteration 95 loss:  0.01646222174167633\n",
            "Iteration 96 loss:  0.014852240681648254\n",
            "Iteration 97 loss:  0.014644371345639229\n",
            "Iteration 98 loss:  0.017870938405394554\n",
            "Iteration 99 loss:  0.01497324307759603\n",
            "Iteration 100 loss:  0.015171314589679241\n",
            "Iteration 101 loss:  0.011167893186211586\n",
            "Iteration 102 loss:  0.011446377262473106\n",
            "Iteration 103 loss:  0.014149476774036884\n",
            "Iteration 104 loss:  0.015281499363481998\n",
            "Iteration 105 loss:  0.015610725618898869\n",
            "Iteration 106 loss:  0.016328871250152588\n",
            "Iteration 107 loss:  0.01693134382367134\n",
            "Iteration 108 loss:  0.01575399562716484\n",
            "Iteration 109 loss:  0.012049547086159388\n",
            "Iteration 110 loss:  0.01399754174053669\n",
            "Iteration 111 loss:  0.014777837321162224\n",
            "Iteration 112 loss:  0.014587152749300003\n",
            "Iteration 113 loss:  0.014876827597618103\n",
            "Iteration 114 loss:  0.012209665961563587\n",
            "Iteration 115 loss:  0.013757279142737389\n",
            "Iteration 116 loss:  0.014614992775022984\n",
            "Iteration 117 loss:  0.010256810113787651\n",
            "Iteration 118 loss:  0.011591554619371891\n",
            "Iteration 119 loss:  0.016860246658325195\n",
            "Iteration 120 loss:  0.011718042194843292\n",
            "Iteration 121 loss:  0.012466637417674065\n",
            "Iteration 122 loss:  0.012492910027503967\n",
            "Iteration 123 loss:  0.014783407561480999\n",
            "Iteration 124 loss:  0.01253374945372343\n",
            "Iteration 125 loss:  0.012555277906358242\n",
            "Iteration 126 loss:  0.010942579247057438\n",
            "Iteration 127 loss:  0.013238227926194668\n",
            "Iteration 128 loss:  0.01240724977105856\n",
            "Iteration 129 loss:  0.01439094046751658\n",
            "Iteration 130 loss:  0.013171300292015076\n",
            "Iteration 131 loss:  0.012178869917988777\n",
            "Iteration 132 loss:  0.012534134089946747\n",
            "Iteration 133 loss:  0.013027679175138474\n",
            "Iteration 134 loss:  0.011565000750124454\n",
            "Iteration 135 loss:  0.012125665321946144\n",
            "Iteration 136 loss:  0.00956566073000431\n",
            "Iteration 137 loss:  0.012732873670756817\n",
            "Iteration 138 loss:  0.01004350557923317\n",
            "Iteration 139 loss:  0.010655866314967474\n",
            "Iteration 140 loss:  0.011524777859449387\n",
            "Iteration 141 loss:  0.010841451585292816\n",
            "Iteration 142 loss:  0.012115687131881714\n",
            "Iteration 143 loss:  0.012530616484582424\n",
            "Iteration 144 loss:  0.009835693053901196\n",
            "Iteration 145 loss:  0.010972368530929089\n",
            "Iteration 146 loss:  0.011370508000254631\n",
            "Iteration 147 loss:  0.010180316865444183\n",
            "Iteration 148 loss:  0.011036631651222706\n",
            "Iteration 149 loss:  0.00859424223502477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.07040365636792212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model without NID"
      ],
      "metadata": {
        "id": "68OZ3pnbCY7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if(graph1_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if(graph1_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if(graph2_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if(graph2_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)# default: sum\n",
        "      graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "      graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "      graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "\n",
        "\n",
        "      # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      # scores_in = torch.t(scores_in)\n",
        "\n",
        "      # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Baseline Model(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Au1iomXeCQ1x",
        "outputId": "9718d125-d573-4a86-93d3-08ce4fb41ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:285: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 loss:  0.054056569933891296\n",
            "Iteration 1 loss:  0.051014892756938934\n",
            "Iteration 2 loss:  0.04683472216129303\n",
            "Iteration 3 loss:  0.046879857778549194\n",
            "Iteration 4 loss:  0.04378516599535942\n",
            "Iteration 5 loss:  0.045759499073028564\n",
            "Iteration 6 loss:  0.038559745997190475\n",
            "Iteration 7 loss:  0.03641315922141075\n",
            "Iteration 8 loss:  0.03851219639182091\n",
            "Iteration 9 loss:  0.04210700591405233\n",
            "Iteration 10 loss:  0.03546161949634552\n",
            "Iteration 11 loss:  0.03782983124256134\n",
            "Iteration 12 loss:  0.03165512904524803\n",
            "Iteration 13 loss:  0.030680999159812927\n",
            "Iteration 14 loss:  0.03331371024250984\n",
            "Iteration 15 loss:  0.0367153026163578\n",
            "Iteration 16 loss:  0.030097467824816704\n",
            "Iteration 17 loss:  0.029855284839868546\n",
            "Iteration 18 loss:  0.03048136830329895\n",
            "Iteration 19 loss:  0.03286177416642507\n",
            "Iteration 20 loss:  0.03122217208147049\n",
            "Iteration 21 loss:  0.03548680245876312\n",
            "Iteration 22 loss:  0.031226422637701035\n",
            "Iteration 23 loss:  0.028772559016942978\n",
            "Iteration 24 loss:  0.03128993883728981\n",
            "Iteration 25 loss:  0.031016867607831955\n",
            "Iteration 26 loss:  0.02781662717461586\n",
            "Iteration 27 loss:  0.027542972937226295\n",
            "Iteration 28 loss:  0.0272406954318285\n",
            "Iteration 29 loss:  0.025591157376766205\n",
            "Iteration 30 loss:  0.025906173512339592\n",
            "Iteration 31 loss:  0.03190566599369049\n",
            "Iteration 32 loss:  0.028349243104457855\n",
            "Iteration 33 loss:  0.027360424399375916\n",
            "Iteration 34 loss:  0.02637695148587227\n",
            "Iteration 35 loss:  0.025163279846310616\n",
            "Iteration 36 loss:  0.027087191119790077\n",
            "Iteration 37 loss:  0.026844022795557976\n",
            "Iteration 38 loss:  0.029109984636306763\n",
            "Iteration 39 loss:  0.027610503137111664\n",
            "Iteration 40 loss:  0.027899060398340225\n",
            "Iteration 41 loss:  0.026015587151050568\n",
            "Iteration 42 loss:  0.024901999160647392\n",
            "Iteration 43 loss:  0.027505848556756973\n",
            "Iteration 44 loss:  0.029321633279323578\n",
            "Iteration 45 loss:  0.02522086538374424\n",
            "Iteration 46 loss:  0.028259674087166786\n",
            "Iteration 47 loss:  0.027325814589858055\n",
            "Iteration 48 loss:  0.024876456707715988\n",
            "Iteration 49 loss:  0.025940880179405212\n",
            "Iteration 50 loss:  0.024536632001399994\n",
            "Iteration 51 loss:  0.027575887739658356\n",
            "Iteration 52 loss:  0.024829747155308723\n",
            "Iteration 53 loss:  0.028654202818870544\n",
            "Iteration 54 loss:  0.026757625862956047\n",
            "Iteration 55 loss:  0.024676162749528885\n",
            "Iteration 56 loss:  0.026535099372267723\n",
            "Iteration 57 loss:  0.024137984961271286\n",
            "Iteration 58 loss:  0.02806813456118107\n",
            "Iteration 59 loss:  0.027703126271565754\n",
            "Iteration 60 loss:  0.025429194793105125\n",
            "Iteration 61 loss:  0.0239491555839777\n",
            "Iteration 62 loss:  0.0241417083889246\n",
            "Iteration 63 loss:  0.025553936138749123\n",
            "Iteration 64 loss:  0.025695858523249626\n",
            "Iteration 65 loss:  0.024883223697543144\n",
            "Iteration 66 loss:  0.026209453120827675\n",
            "Iteration 67 loss:  0.029834646731615067\n",
            "Iteration 68 loss:  0.02800629287958145\n",
            "Iteration 69 loss:  0.024896306296189625\n",
            "Iteration 70 loss:  0.027128932997584343\n",
            "Iteration 71 loss:  0.027368849143385887\n",
            "Iteration 72 loss:  0.02793421968817711\n",
            "Iteration 73 loss:  0.022712640464305878\n",
            "Iteration 74 loss:  0.026528839021921158\n",
            "Iteration 75 loss:  0.025637183338403702\n",
            "Iteration 76 loss:  0.02239820919930935\n",
            "Iteration 77 loss:  0.025294411927461624\n",
            "Iteration 78 loss:  0.026306770741939545\n",
            "Iteration 79 loss:  0.023918400208155315\n",
            "Iteration 80 loss:  0.024919267743825912\n",
            "Iteration 81 loss:  0.023777645081281662\n",
            "Iteration 82 loss:  0.02224556729197502\n",
            "Iteration 83 loss:  0.02456405572593212\n",
            "Iteration 84 loss:  0.027202675119042397\n",
            "Iteration 85 loss:  0.028596505522727966\n",
            "Iteration 86 loss:  0.026448193937540054\n",
            "Iteration 87 loss:  0.025983797386288643\n",
            "Iteration 88 loss:  0.02500719204545021\n",
            "Iteration 89 loss:  0.025983522335688274\n",
            "Iteration 90 loss:  0.027583874762058258\n",
            "Iteration 91 loss:  0.027755223214626312\n",
            "Iteration 92 loss:  0.025716952979564667\n",
            "Iteration 93 loss:  0.02484092116355896\n",
            "Iteration 94 loss:  0.02394469641149044\n",
            "Iteration 95 loss:  0.024784263223409653\n",
            "Iteration 96 loss:  0.026108942925930023\n",
            "Iteration 97 loss:  0.02650635316967964\n",
            "Iteration 98 loss:  0.02213083952665329\n",
            "Iteration 99 loss:  0.020238517473141353\n",
            "Iteration 100 loss:  0.023539533838629723\n",
            "Iteration 101 loss:  0.026663705706596375\n",
            "Iteration 102 loss:  0.027403052896261215\n",
            "Iteration 103 loss:  0.028991861268877983\n",
            "Iteration 104 loss:  0.02346898801624775\n",
            "Iteration 105 loss:  0.02482766844332218\n",
            "Iteration 106 loss:  0.022796805948019028\n",
            "Iteration 107 loss:  0.023620717227458954\n",
            "Iteration 108 loss:  0.023013891652226448\n",
            "Iteration 109 loss:  0.030356983343760174\n",
            "Iteration 110 loss:  0.02945863828063011\n",
            "Iteration 111 loss:  0.024210313335061073\n",
            "Iteration 112 loss:  0.02533949539065361\n",
            "Iteration 113 loss:  0.024522846564650536\n",
            "Iteration 114 loss:  0.024230636656284332\n",
            "Iteration 115 loss:  0.022275706753134727\n",
            "Iteration 116 loss:  0.02596796676516533\n",
            "Iteration 117 loss:  0.02522384189069271\n",
            "Iteration 118 loss:  0.025570383295416832\n",
            "Iteration 119 loss:  0.020829121271769207\n",
            "Iteration 120 loss:  0.023345915600657463\n",
            "Iteration 121 loss:  0.027608679607510567\n",
            "Iteration 122 loss:  0.023959064856171608\n",
            "Iteration 123 loss:  0.02929946407675743\n",
            "Iteration 124 loss:  0.02660788595676422\n",
            "Iteration 125 loss:  0.019733158871531487\n",
            "Iteration 126 loss:  0.021734263747930527\n",
            "Iteration 127 loss:  0.02653718926012516\n",
            "Iteration 128 loss:  0.02636943943798542\n",
            "Iteration 129 loss:  0.022565066814422607\n",
            "Iteration 130 loss:  0.026404263451695442\n",
            "Iteration 131 loss:  0.024837614968419075\n",
            "Iteration 132 loss:  0.024588599801063538\n",
            "Iteration 133 loss:  0.021231448277831078\n",
            "Iteration 134 loss:  0.026205746456980705\n",
            "Iteration 135 loss:  0.02234429307281971\n",
            "Iteration 136 loss:  0.029563145712018013\n",
            "Iteration 137 loss:  0.023706307634711266\n",
            "Iteration 138 loss:  0.02424049936234951\n",
            "Iteration 139 loss:  0.02596934139728546\n",
            "Iteration 140 loss:  0.022266143932938576\n",
            "Iteration 141 loss:  0.026110177859663963\n",
            "Iteration 142 loss:  0.029407627880573273\n",
            "Iteration 143 loss:  0.02612978406250477\n",
            "Iteration 144 loss:  0.026160525158047676\n",
            "Iteration 145 loss:  0.023306479677557945\n",
            "Iteration 146 loss:  0.024106936529278755\n",
            "Iteration 147 loss:  0.023861093446612358\n",
            "Iteration 148 loss:  0.021265478804707527\n",
            "Iteration 149 loss:  0.025113843381404877\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.09214979596436024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAX Pooling"
      ],
      "metadata": {
        "id": "2Lfo0x9TChNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if graph1_hidden1[i][0] >= 10:# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if graph1_hidden2[i][0] >= 50:# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if graph2_hidden1[i][0] >= 10:# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if graph2_hidden2[i][0] >= 50:# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled = torch.max(graph1_01concat, 0)\n",
        "      graph2_01pooled = torch.max(graph2_01concat, 0)\n",
        "      graph1_12pooled = torch.max(graph1_12concat, 0)\n",
        "      graph2_12pooled = torch.max(graph2_12concat, 0)\n",
        "\n",
        "      graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "      graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "      graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "      graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "      scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      scores_in = torch.t(scores_in)\n",
        "\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_in, score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MAX Pooling(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xsjve2chCWrc",
        "outputId": "7aa325a8-858e-4e52-d063-46765e8a999d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.12628981471061707\n",
            "Iteration 1 loss:  0.1308736503124237\n",
            "Iteration 2 loss:  0.12390418350696564\n",
            "Iteration 3 loss:  0.1258573979139328\n",
            "Iteration 4 loss:  0.12566497921943665\n",
            "Iteration 5 loss:  0.12688492238521576\n",
            "Iteration 6 loss:  0.12949281930923462\n",
            "Iteration 7 loss:  0.1285911500453949\n",
            "Iteration 8 loss:  0.12258028984069824\n",
            "Iteration 9 loss:  0.12152093648910522\n",
            "Iteration 10 loss:  0.12969329953193665\n",
            "Iteration 11 loss:  0.12117205560207367\n",
            "Iteration 12 loss:  0.12068643420934677\n",
            "Iteration 13 loss:  0.11890845000743866\n",
            "Iteration 14 loss:  0.11613453179597855\n",
            "Iteration 15 loss:  0.1242954283952713\n",
            "Iteration 16 loss:  0.12057875841856003\n",
            "Iteration 17 loss:  0.11543092876672745\n",
            "Iteration 18 loss:  0.11224902421236038\n",
            "Iteration 19 loss:  0.12885522842407227\n",
            "Iteration 20 loss:  0.10651315003633499\n",
            "Iteration 21 loss:  0.1104431077837944\n",
            "Iteration 22 loss:  0.11649541556835175\n",
            "Iteration 23 loss:  0.1163434088230133\n",
            "Iteration 24 loss:  0.11575008183717728\n",
            "Iteration 25 loss:  0.11417894810438156\n",
            "Iteration 26 loss:  0.11221958696842194\n",
            "Iteration 27 loss:  0.1054149866104126\n",
            "Iteration 28 loss:  0.10756184160709381\n",
            "Iteration 29 loss:  0.11821966369946797\n",
            "Iteration 30 loss:  0.10475651919841766\n",
            "Iteration 31 loss:  0.10307970643043518\n",
            "Iteration 32 loss:  0.09594380110502243\n",
            "Iteration 33 loss:  0.10146596282720566\n",
            "Iteration 34 loss:  0.1071251854300499\n",
            "Iteration 35 loss:  0.10524089634418488\n",
            "Iteration 36 loss:  0.09503733366727829\n",
            "Iteration 37 loss:  0.09327255934476852\n",
            "Iteration 38 loss:  0.09719768166542053\n",
            "Iteration 39 loss:  0.09054144223531087\n",
            "Iteration 40 loss:  0.09418435394763947\n",
            "Iteration 41 loss:  0.08466510474681854\n",
            "Iteration 42 loss:  0.08777833729982376\n",
            "Iteration 43 loss:  0.08203261345624924\n",
            "Iteration 44 loss:  0.08631347864866257\n",
            "Iteration 45 loss:  0.08478543907403946\n",
            "Iteration 46 loss:  0.07837099581956863\n",
            "Iteration 47 loss:  0.08098692446947098\n",
            "Iteration 48 loss:  0.07503623515367508\n",
            "Iteration 49 loss:  0.07623676458994548\n",
            "Iteration 50 loss:  0.07201908528804779\n",
            "Iteration 51 loss:  0.0701352059841156\n",
            "Iteration 52 loss:  0.0711914524435997\n",
            "Iteration 53 loss:  0.06287834793329239\n",
            "Iteration 54 loss:  0.0657385066151619\n",
            "Iteration 55 loss:  0.06462490558624268\n",
            "Iteration 56 loss:  0.061076581478118896\n",
            "Iteration 57 loss:  0.06387263536453247\n",
            "Iteration 58 loss:  0.05468592047691345\n",
            "Iteration 59 loss:  0.05087174475193024\n",
            "Iteration 60 loss:  0.051689423620700836\n",
            "Iteration 61 loss:  0.053113337606191635\n",
            "Iteration 62 loss:  0.050812628120183945\n",
            "Iteration 63 loss:  0.0508883111178875\n",
            "Iteration 64 loss:  0.05387090519070625\n",
            "Iteration 65 loss:  0.04759545624256134\n",
            "Iteration 66 loss:  0.04510029777884483\n",
            "Iteration 67 loss:  0.0495210699737072\n",
            "Iteration 68 loss:  0.040202368050813675\n",
            "Iteration 69 loss:  0.037539723018805184\n",
            "Iteration 70 loss:  0.0431860126554966\n",
            "Iteration 71 loss:  0.045673783868551254\n",
            "Iteration 72 loss:  0.04098755866289139\n",
            "Iteration 73 loss:  0.03631369397044182\n",
            "Iteration 74 loss:  0.04118770733475685\n",
            "Iteration 75 loss:  0.04011117294430733\n",
            "Iteration 76 loss:  0.037615057080984116\n",
            "Iteration 77 loss:  0.03951633721590042\n",
            "Iteration 78 loss:  0.033878814429044724\n",
            "Iteration 79 loss:  0.03739807258049647\n",
            "Iteration 80 loss:  0.039217885583639145\n",
            "Iteration 81 loss:  0.039926689118146896\n",
            "Iteration 82 loss:  0.02884734608232975\n",
            "Iteration 83 loss:  0.040071919560432434\n",
            "Iteration 84 loss:  0.034558191895484924\n",
            "Iteration 85 loss:  0.038519538938999176\n",
            "Iteration 86 loss:  0.034139882773160934\n",
            "Iteration 87 loss:  0.03448593243956566\n",
            "Iteration 88 loss:  0.03156782686710358\n",
            "Iteration 89 loss:  0.03318278739849726\n",
            "Iteration 90 loss:  0.034899525344371796\n",
            "Iteration 91 loss:  0.03072970174252987\n",
            "Iteration 92 loss:  0.035475727170705795\n",
            "Iteration 93 loss:  0.03270876407623291\n",
            "Iteration 94 loss:  0.031685419380664825\n",
            "Iteration 95 loss:  0.03480818495154381\n",
            "Iteration 96 loss:  0.034143850207328796\n",
            "Iteration 97 loss:  0.03409566357731819\n",
            "Iteration 98 loss:  0.03140103071928024\n",
            "Iteration 99 loss:  0.028449455897013348\n",
            "Iteration 100 loss:  0.030813051387667656\n",
            "Iteration 101 loss:  0.0349465049803257\n",
            "Iteration 102 loss:  0.02691511996090412\n",
            "Iteration 103 loss:  0.03659658133983612\n",
            "Iteration 104 loss:  0.027425026521086693\n",
            "Iteration 105 loss:  0.0321529246866703\n",
            "Iteration 106 loss:  0.03222883865237236\n",
            "Iteration 107 loss:  0.027234481647610664\n",
            "Iteration 108 loss:  0.03306950256228447\n",
            "Iteration 109 loss:  0.0296082670489947\n",
            "Iteration 110 loss:  0.031144656240940094\n",
            "Iteration 111 loss:  0.031331323087215424\n",
            "Iteration 112 loss:  0.029942171648144722\n",
            "Iteration 113 loss:  0.02681361511349678\n",
            "Iteration 114 loss:  0.027035893872380257\n",
            "Iteration 115 loss:  0.03462192788720131\n",
            "Iteration 116 loss:  0.027549734339118004\n",
            "Iteration 117 loss:  0.02788148634135723\n",
            "Iteration 118 loss:  0.02784094586968422\n",
            "Iteration 119 loss:  0.032495242853959404\n",
            "Iteration 120 loss:  0.027188129723072052\n",
            "Iteration 121 loss:  0.03045535832643509\n",
            "Iteration 122 loss:  0.02491866424679756\n",
            "Iteration 123 loss:  0.02772248350083828\n",
            "Iteration 124 loss:  0.028170743957161903\n",
            "Iteration 125 loss:  0.02669384703040123\n",
            "Iteration 126 loss:  0.027636615559458733\n",
            "Iteration 127 loss:  0.028748083859682083\n",
            "Iteration 128 loss:  0.030532363802194595\n",
            "Iteration 129 loss:  0.02595343440771103\n",
            "Iteration 130 loss:  0.02496625855565071\n",
            "Iteration 131 loss:  0.02715918980538845\n",
            "Iteration 132 loss:  0.026185616850852966\n",
            "Iteration 133 loss:  0.024740107357501984\n",
            "Iteration 134 loss:  0.029089411720633507\n",
            "Iteration 135 loss:  0.026415744796395302\n",
            "Iteration 136 loss:  0.028634632006287575\n",
            "Iteration 137 loss:  0.02660965919494629\n",
            "Iteration 138 loss:  0.02382853254675865\n",
            "Iteration 139 loss:  0.025067436198393505\n",
            "Iteration 140 loss:  0.0267691258341074\n",
            "Iteration 141 loss:  0.026392869651317596\n",
            "Iteration 142 loss:  0.027173178270459175\n",
            "Iteration 143 loss:  0.026481177657842636\n",
            "Iteration 144 loss:  0.02408396266400814\n",
            "Iteration 145 loss:  0.024562647566199303\n",
            "Iteration 146 loss:  0.022429151460528374\n",
            "Iteration 147 loss:  0.024422140792012215\n",
            "Iteration 148 loss:  0.023211784660816193\n",
            "Iteration 149 loss:  0.02120097478230794\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.10831566401438544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MIN Pooling"
      ],
      "metadata": {
        "id": "ZuoWGguXCpef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if(graph1_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if(graph1_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if(graph2_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if(graph2_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled, min_idxs = torch.min(graph1_01concat, 0)\n",
        "      graph2_01pooled, min_idxs = torch.min(graph2_01concat, 0)\n",
        "      graph1_12pooled, min_idxs = torch.min(graph1_12concat, 0)\n",
        "      graph2_12pooled, min_idxs = torch.min(graph2_12concat, 0)\n",
        "\n",
        "      graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "      graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "      graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "      graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "      scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      scores_in = torch.t(scores_in)\n",
        "\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_in, score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MIN Pooling(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qxUbMh8xCWok",
        "outputId": "0fbd5398-2741-4980-c9f3-961dbe75622f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.12118370831012726\n",
            "Iteration 1 loss:  0.12562806904315948\n",
            "Iteration 2 loss:  0.11973835527896881\n",
            "Iteration 3 loss:  0.12269765883684158\n",
            "Iteration 4 loss:  0.12190108746290207\n",
            "Iteration 5 loss:  0.11614497750997543\n",
            "Iteration 6 loss:  0.11585038155317307\n",
            "Iteration 7 loss:  0.11627326905727386\n",
            "Iteration 8 loss:  0.1064031794667244\n",
            "Iteration 9 loss:  0.11315175890922546\n",
            "Iteration 10 loss:  0.10525640100240707\n",
            "Iteration 11 loss:  0.10910685360431671\n",
            "Iteration 12 loss:  0.11819104850292206\n",
            "Iteration 13 loss:  0.10980746895074844\n",
            "Iteration 14 loss:  0.11732365190982819\n",
            "Iteration 15 loss:  0.10743038356304169\n",
            "Iteration 16 loss:  0.12114939838647842\n",
            "Iteration 17 loss:  0.10965895652770996\n",
            "Iteration 18 loss:  0.11257431656122208\n",
            "Iteration 19 loss:  0.11687317490577698\n",
            "Iteration 20 loss:  0.10755234211683273\n",
            "Iteration 21 loss:  0.11232852190732956\n",
            "Iteration 22 loss:  0.10825321078300476\n",
            "Iteration 23 loss:  0.10595335066318512\n",
            "Iteration 24 loss:  0.10607455670833588\n",
            "Iteration 25 loss:  0.09667063504457474\n",
            "Iteration 26 loss:  0.11516503244638443\n",
            "Iteration 27 loss:  0.11125762015581131\n",
            "Iteration 28 loss:  0.10329441726207733\n",
            "Iteration 29 loss:  0.1015418569246928\n",
            "Iteration 30 loss:  0.09818851202726364\n",
            "Iteration 31 loss:  0.10834042727947235\n",
            "Iteration 32 loss:  0.09730323404073715\n",
            "Iteration 33 loss:  0.10962580144405365\n",
            "Iteration 34 loss:  0.09975580871105194\n",
            "Iteration 35 loss:  0.10113493353128433\n",
            "Iteration 36 loss:  0.10134479403495789\n",
            "Iteration 37 loss:  0.0997808650135994\n",
            "Iteration 38 loss:  0.10662324726581573\n",
            "Iteration 39 loss:  0.10057348012924194\n",
            "Iteration 40 loss:  0.10325837135314941\n",
            "Iteration 41 loss:  0.10158479958772659\n",
            "Iteration 42 loss:  0.09528481960296631\n",
            "Iteration 43 loss:  0.09566917270421982\n",
            "Iteration 44 loss:  0.09765695780515671\n",
            "Iteration 45 loss:  0.09571661800146103\n",
            "Iteration 46 loss:  0.10064219683408737\n",
            "Iteration 47 loss:  0.09774820506572723\n",
            "Iteration 48 loss:  0.09793215245008469\n",
            "Iteration 49 loss:  0.09446920951207478\n",
            "Iteration 50 loss:  0.1014552116394043\n",
            "Iteration 51 loss:  0.09620436280965805\n",
            "Iteration 52 loss:  0.09501791000366211\n",
            "Iteration 53 loss:  0.09471774846315384\n",
            "Iteration 54 loss:  0.09482789039611816\n",
            "Iteration 55 loss:  0.09681051969528198\n",
            "Iteration 56 loss:  0.09404124319553375\n",
            "Iteration 57 loss:  0.08983661979436874\n",
            "Iteration 58 loss:  0.09005850553512573\n",
            "Iteration 59 loss:  0.07759664456049602\n",
            "Iteration 60 loss:  0.09136895835399628\n",
            "Iteration 61 loss:  0.09431809931993484\n",
            "Iteration 62 loss:  0.0884818583726883\n",
            "Iteration 63 loss:  0.09343701601028442\n",
            "Iteration 64 loss:  0.0923881083726883\n",
            "Iteration 65 loss:  0.09151554107666016\n",
            "Iteration 66 loss:  0.08460795134305954\n",
            "Iteration 67 loss:  0.08901239186525345\n",
            "Iteration 68 loss:  0.08561719954013824\n",
            "Iteration 69 loss:  0.08806410431861877\n",
            "Iteration 70 loss:  0.0860612541437149\n",
            "Iteration 71 loss:  0.08618113398551941\n",
            "Iteration 72 loss:  0.09664725512266159\n",
            "Iteration 73 loss:  0.09444452077150345\n",
            "Iteration 74 loss:  0.08703567087650299\n",
            "Iteration 75 loss:  0.0853317528963089\n",
            "Iteration 76 loss:  0.08231125771999359\n",
            "Iteration 77 loss:  0.08201265335083008\n",
            "Iteration 78 loss:  0.07656112313270569\n",
            "Iteration 79 loss:  0.08998254934946696\n",
            "Iteration 80 loss:  0.0844118595123291\n",
            "Iteration 81 loss:  0.08483104407787323\n",
            "Iteration 82 loss:  0.08682410418987274\n",
            "Iteration 83 loss:  0.08836481720209122\n",
            "Iteration 84 loss:  0.07475347071886063\n",
            "Iteration 85 loss:  0.07533607631921768\n",
            "Iteration 86 loss:  0.08300124108791351\n",
            "Iteration 87 loss:  0.08514855802059174\n",
            "Iteration 88 loss:  0.08220262825489044\n",
            "Iteration 89 loss:  0.08740104238192241\n",
            "Iteration 90 loss:  0.08685141056776047\n",
            "Iteration 91 loss:  0.08135291934013367\n",
            "Iteration 92 loss:  0.0779583677649498\n",
            "Iteration 93 loss:  0.08154195547103882\n",
            "Iteration 94 loss:  0.08233081549406052\n",
            "Iteration 95 loss:  0.07862267643213272\n",
            "Iteration 96 loss:  0.0771055668592453\n",
            "Iteration 97 loss:  0.074984610080719\n",
            "Iteration 98 loss:  0.07238227874040604\n",
            "Iteration 99 loss:  0.07910510897636414\n",
            "Iteration 100 loss:  0.07071097940206528\n",
            "Iteration 101 loss:  0.08368217945098877\n",
            "Iteration 102 loss:  0.07973036170005798\n",
            "Iteration 103 loss:  0.07832524180412292\n",
            "Iteration 104 loss:  0.06958063691854477\n",
            "Iteration 105 loss:  0.07544542849063873\n",
            "Iteration 106 loss:  0.07366836071014404\n",
            "Iteration 107 loss:  0.07147515565156937\n",
            "Iteration 108 loss:  0.07189816236495972\n",
            "Iteration 109 loss:  0.07960773011048634\n",
            "Iteration 110 loss:  0.0661594569683075\n",
            "Iteration 111 loss:  0.07581723481416702\n",
            "Iteration 112 loss:  0.07332305610179901\n",
            "Iteration 113 loss:  0.06951654702425003\n",
            "Iteration 114 loss:  0.07195142656564713\n",
            "Iteration 115 loss:  0.0698641911149025\n",
            "Iteration 116 loss:  0.071518175303936\n",
            "Iteration 117 loss:  0.06996993720531464\n",
            "Iteration 118 loss:  0.06677260249853134\n",
            "Iteration 119 loss:  0.07567318280537923\n",
            "Iteration 120 loss:  0.06677542626857758\n",
            "Iteration 121 loss:  0.06913114339113235\n",
            "Iteration 122 loss:  0.06809231638908386\n",
            "Iteration 123 loss:  0.07060769945383072\n",
            "Iteration 124 loss:  0.06369582563638687\n",
            "Iteration 125 loss:  0.06274018436670303\n",
            "Iteration 126 loss:  0.06570442020893097\n",
            "Iteration 127 loss:  0.06692120432853699\n",
            "Iteration 128 loss:  0.06091678887605667\n",
            "Iteration 129 loss:  0.06616343557834625\n",
            "Iteration 130 loss:  0.06523104012012482\n",
            "Iteration 131 loss:  0.06389188021421432\n",
            "Iteration 132 loss:  0.05463140830397606\n",
            "Iteration 133 loss:  0.06128982827067375\n",
            "Iteration 134 loss:  0.06024604290723801\n",
            "Iteration 135 loss:  0.06506557762622833\n",
            "Iteration 136 loss:  0.06397169828414917\n",
            "Iteration 137 loss:  0.06114272028207779\n",
            "Iteration 138 loss:  0.05455353111028671\n",
            "Iteration 139 loss:  0.05949963132540385\n",
            "Iteration 140 loss:  0.061610788106918335\n",
            "Iteration 141 loss:  0.058518681675195694\n",
            "Iteration 142 loss:  0.06302762031555176\n",
            "Iteration 143 loss:  0.055278461426496506\n",
            "Iteration 144 loss:  0.05779630318284035\n",
            "Iteration 145 loss:  0.051863979548215866\n",
            "Iteration 146 loss:  0.055485304445028305\n",
            "Iteration 147 loss:  0.04889470338821411\n",
            "Iteration 148 loss:  0.05432121083140373\n",
            "Iteration 149 loss:  0.05190749963124593\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.10819407567942108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MEAN Pooling"
      ],
      "metadata": {
        "id": "PKVQveHbCp32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if(graph1_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if(graph1_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if(graph2_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if(graph2_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled = torch.mean(graph1_01concat, 0)\n",
        "      graph2_01pooled = torch.mean(graph2_01concat, 0)\n",
        "      graph1_12pooled = torch.mean(graph1_12concat, 0)\n",
        "      graph2_12pooled = torch.mean(graph2_12concat, 0)\n",
        "\n",
        "      graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "      graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "      graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "      graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "      scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      scores_in = torch.t(scores_in)\n",
        "\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_in, score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MEAN Pooling(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bS_fzz0aCWlh",
        "outputId": "7a0809f9-4478-4aa9-83e2-21eaffd05205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.10026467591524124\n",
            "Iteration 1 loss:  0.09548036009073257\n",
            "Iteration 2 loss:  0.09771028161048889\n",
            "Iteration 3 loss:  0.09457293152809143\n",
            "Iteration 4 loss:  0.10288415104150772\n",
            "Iteration 5 loss:  0.0969654768705368\n",
            "Iteration 6 loss:  0.09299112111330032\n",
            "Iteration 7 loss:  0.10436959564685822\n",
            "Iteration 8 loss:  0.0922425165772438\n",
            "Iteration 9 loss:  0.09498655796051025\n",
            "Iteration 10 loss:  0.09384260326623917\n",
            "Iteration 11 loss:  0.08875134587287903\n",
            "Iteration 12 loss:  0.08705342561006546\n",
            "Iteration 13 loss:  0.08660426735877991\n",
            "Iteration 14 loss:  0.09747948497533798\n",
            "Iteration 15 loss:  0.0938953086733818\n",
            "Iteration 16 loss:  0.09381624311208725\n",
            "Iteration 17 loss:  0.09251498430967331\n",
            "Iteration 18 loss:  0.08277371525764465\n",
            "Iteration 19 loss:  0.090304434299469\n",
            "Iteration 20 loss:  0.08933785557746887\n",
            "Iteration 21 loss:  0.08761174231767654\n",
            "Iteration 22 loss:  0.08571135252714157\n",
            "Iteration 23 loss:  0.08220931142568588\n",
            "Iteration 24 loss:  0.0844062939286232\n",
            "Iteration 25 loss:  0.092805415391922\n",
            "Iteration 26 loss:  0.0806945264339447\n",
            "Iteration 27 loss:  0.08929506689310074\n",
            "Iteration 28 loss:  0.0760129988193512\n",
            "Iteration 29 loss:  0.08098928133646648\n",
            "Iteration 30 loss:  0.08829420059919357\n",
            "Iteration 31 loss:  0.07970605790615082\n",
            "Iteration 32 loss:  0.08527621626853943\n",
            "Iteration 33 loss:  0.07543466985225677\n",
            "Iteration 34 loss:  0.07832532376050949\n",
            "Iteration 35 loss:  0.0792003870010376\n",
            "Iteration 36 loss:  0.07319898158311844\n",
            "Iteration 37 loss:  0.08147294819355011\n",
            "Iteration 38 loss:  0.07472925633192062\n",
            "Iteration 39 loss:  0.08860425154368083\n",
            "Iteration 40 loss:  0.07891195267438889\n",
            "Iteration 41 loss:  0.07513046264648438\n",
            "Iteration 42 loss:  0.07006020098924637\n",
            "Iteration 43 loss:  0.0760093629360199\n",
            "Iteration 44 loss:  0.07225091010332108\n",
            "Iteration 45 loss:  0.07776089757680893\n",
            "Iteration 46 loss:  0.07142608612775803\n",
            "Iteration 47 loss:  0.07690650969743729\n",
            "Iteration 48 loss:  0.07403145730495453\n",
            "Iteration 49 loss:  0.07228696346282959\n",
            "Iteration 50 loss:  0.0719880610704422\n",
            "Iteration 51 loss:  0.06774498522281647\n",
            "Iteration 52 loss:  0.062089599668979645\n",
            "Iteration 53 loss:  0.07577512413263321\n",
            "Iteration 54 loss:  0.06816758215427399\n",
            "Iteration 55 loss:  0.07102073729038239\n",
            "Iteration 56 loss:  0.06867948919534683\n",
            "Iteration 57 loss:  0.06726962327957153\n",
            "Iteration 58 loss:  0.07172564417123795\n",
            "Iteration 59 loss:  0.06976129114627838\n",
            "Iteration 60 loss:  0.06869012862443924\n",
            "Iteration 61 loss:  0.0664362758398056\n",
            "Iteration 62 loss:  0.06733277440071106\n",
            "Iteration 63 loss:  0.06705508381128311\n",
            "Iteration 64 loss:  0.06557516008615494\n",
            "Iteration 65 loss:  0.06094728410243988\n",
            "Iteration 66 loss:  0.06026194617152214\n",
            "Iteration 67 loss:  0.059874121099710464\n",
            "Iteration 68 loss:  0.06026649847626686\n",
            "Iteration 69 loss:  0.06087293724219004\n",
            "Iteration 70 loss:  0.057710085064172745\n",
            "Iteration 71 loss:  0.06459566950798035\n",
            "Iteration 72 loss:  0.05736742541193962\n",
            "Iteration 73 loss:  0.06137815862894058\n",
            "Iteration 74 loss:  0.054951030761003494\n",
            "Iteration 75 loss:  0.056470856070518494\n",
            "Iteration 76 loss:  0.05799895524978638\n",
            "Iteration 77 loss:  0.053521160036325455\n",
            "Iteration 78 loss:  0.05958106368780136\n",
            "Iteration 79 loss:  0.06054507692654928\n",
            "Iteration 80 loss:  0.05517633631825447\n",
            "Iteration 81 loss:  0.0579681470990181\n",
            "Iteration 82 loss:  0.05761284381151199\n",
            "Iteration 83 loss:  0.050633642822504044\n",
            "Iteration 84 loss:  0.05252569913864136\n",
            "Iteration 85 loss:  0.04755311831831932\n",
            "Iteration 86 loss:  0.05532502755522728\n",
            "Iteration 87 loss:  0.04995749890804291\n",
            "Iteration 88 loss:  0.04970564320683479\n",
            "Iteration 89 loss:  0.05205442011356354\n",
            "Iteration 90 loss:  0.05400353670120239\n",
            "Iteration 91 loss:  0.05267035588622093\n",
            "Iteration 92 loss:  0.048481591045856476\n",
            "Iteration 93 loss:  0.04658430442214012\n",
            "Iteration 94 loss:  0.047729846090078354\n",
            "Iteration 95 loss:  0.04494708776473999\n",
            "Iteration 96 loss:  0.047300517559051514\n",
            "Iteration 97 loss:  0.04692520573735237\n",
            "Iteration 98 loss:  0.0486062653362751\n",
            "Iteration 99 loss:  0.04801322023073832\n",
            "Iteration 100 loss:  0.04953339695930481\n",
            "Iteration 101 loss:  0.043669749051332474\n",
            "Iteration 102 loss:  0.04775085300207138\n",
            "Iteration 103 loss:  0.04703317582607269\n",
            "Iteration 104 loss:  0.049178317189216614\n",
            "Iteration 105 loss:  0.04735442250967026\n",
            "Iteration 106 loss:  0.043858472257852554\n",
            "Iteration 107 loss:  0.04647127538919449\n",
            "Iteration 108 loss:  0.038806695491075516\n",
            "Iteration 109 loss:  0.03922302772601446\n",
            "Iteration 110 loss:  0.044737234711647034\n",
            "Iteration 111 loss:  0.04160206764936447\n",
            "Iteration 112 loss:  0.04403375834226608\n",
            "Iteration 113 loss:  0.04197511076927185\n",
            "Iteration 114 loss:  0.04397667571902275\n",
            "Iteration 115 loss:  0.04581751674413681\n",
            "Iteration 116 loss:  0.044151756912469864\n",
            "Iteration 117 loss:  0.04413723573088646\n",
            "Iteration 118 loss:  0.04901738092303276\n",
            "Iteration 119 loss:  0.03991592427094778\n",
            "Iteration 120 loss:  0.04835202544927597\n",
            "Iteration 121 loss:  0.04325775429606438\n",
            "Iteration 122 loss:  0.040490470826625824\n",
            "Iteration 123 loss:  0.04579126462340355\n",
            "Iteration 124 loss:  0.040439166128635406\n",
            "Iteration 125 loss:  0.043256647884845734\n",
            "Iteration 126 loss:  0.041299380362033844\n",
            "Iteration 127 loss:  0.04392101243138313\n",
            "Iteration 128 loss:  0.042738012969493866\n",
            "Iteration 129 loss:  0.04330576956272125\n",
            "Iteration 130 loss:  0.040715523064136505\n",
            "Iteration 131 loss:  0.04559890925884247\n",
            "Iteration 132 loss:  0.039434079080820084\n",
            "Iteration 133 loss:  0.04275364428758621\n",
            "Iteration 134 loss:  0.04425032064318657\n",
            "Iteration 135 loss:  0.043204937130212784\n",
            "Iteration 136 loss:  0.04061853885650635\n",
            "Iteration 137 loss:  0.040594685822725296\n",
            "Iteration 138 loss:  0.04715852439403534\n",
            "Iteration 139 loss:  0.03793340424696604\n",
            "Iteration 140 loss:  0.04459281265735626\n",
            "Iteration 141 loss:  0.043283045291900635\n",
            "Iteration 142 loss:  0.042945463210344315\n",
            "Iteration 143 loss:  0.04103871434926987\n",
            "Iteration 144 loss:  0.034607697278261185\n",
            "Iteration 145 loss:  0.04195329174399376\n",
            "Iteration 146 loss:  0.04167696833610535\n",
            "Iteration 147 loss:  0.040726929903030396\n",
            "Iteration 148 loss:  0.04633622616529465\n",
            "Iteration 149 loss:  0.039187235136826835\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.08894195284977156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SUM Pooling"
      ],
      "metadata": {
        "id": "kdZAx8ruCqx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        # self.number_of_node_labels = len(number_of_node_labels)\n",
        "        # self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 11)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 60)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "      adj_1 = torch.FloatTensor(np.array(label_multiset[\"edge_index_1\"].todense()))\n",
        "      adj_2 = torch.FloatTensor(np.array(label_multiset[\"edge_index_2\"].todense()))\n",
        "      features_1, features_2 = label_multiset[\"features_1\"], label_multiset[\"features_2\"]\n",
        "      \n",
        "      graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, features_1)#\n",
        "      graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, features_2)#\n",
        "    \n",
        "      Graph1_hidden1, Graph1_hidden2, Graph2_hidden1, Graph2_hidden2 = [], [], [], []\n",
        "      for i in range(graph1_hidden1.size()[0]):\n",
        "        if(graph1_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden1.append([0.0]*9 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden1.append([1.0 if graph1_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "        if(graph1_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "            Graph1_hidden2.append([0.0]*49 + [1.0])\n",
        "        else:\n",
        "            Graph1_hidden2.append([1.0 if graph1_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "\n",
        "      for i in range(graph2_hidden1.size()[0]):\n",
        "          if(graph2_hidden1[i][0] >= 10):# 10 for imdb; 6 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden1.append([0.0]*9 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden1.append([1.0 if graph2_hidden1[i][0] == j else 0.0 for j in range(10)])\n",
        "\n",
        "          if(graph2_hidden2[i][0] >= 50):# 50 for imdb; 15 for linux # the valus here can be set by the users\n",
        "              Graph2_hidden2.append([0.0]*49 + [1.0])\n",
        "          else:\n",
        "              Graph2_hidden2.append([1.0 if graph2_hidden2[i][0] == j else 0.0 for j in range(50)])\n",
        "      Graph1_hidden1, Graph1_hidden2 = torch.FloatTensor(np.array(Graph1_hidden1)), torch.FloatTensor(np.array(Graph1_hidden2))\n",
        "      Graph2_hidden1, Graph2_hidden2 = torch.FloatTensor(np.array(Graph2_hidden1)), torch.FloatTensor(np.array(Graph2_hidden2))\n",
        "\n",
        "      graph1_01concat = torch.cat([features_1, Graph1_hidden1], dim=1)\n",
        "      graph2_01concat = torch.cat([features_2, Graph2_hidden1], dim=1)\n",
        "      graph1_12concat = torch.cat([Graph1_hidden1, Graph1_hidden2], dim=1)\n",
        "      graph2_12concat = torch.cat([Graph2_hidden1, Graph2_hidden2], dim=1)\n",
        "\n",
        "      graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)# default: sum\n",
        "      graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "      graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "      graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "\n",
        "\n",
        "      scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "      scores_in = torch.t(scores_in)\n",
        "\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "      scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "      score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "      scores_ec = self.tensor_network_ec(graph1_12pooled, graph2_12pooled)\n",
        "      scores_ec = torch.t(scores_ec)\n",
        "\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "      scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "      score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "      return torch.cat([score_in, score_ec], dim=1)\n",
        "        # adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "        #     np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        # edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        # node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        # edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        # #gal\n",
        "        # graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        # graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        # edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        # edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        # #node level embedding Concatenation\n",
        "        # graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        # graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        # graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        # graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        # #graph pooling: node Sum\n",
        "        # graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        # graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        # graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        # graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        # #edge level embedding Concatenation\n",
        "        # edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        # edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        # #graph pooling: edge Sum\n",
        "        # edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        # edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # # scores_nc = torch.t(scores_nc)\n",
        "        # #\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # # scores_ie = torch.t(scores_ie)\n",
        "        # #\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        # scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        # scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        # scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        # score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        # return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2= [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0])\n",
        "\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        label_multiset[\"edge_index_1\"], label_multiset[\"edge_index_2\"] = nx.adjacency_matrix(graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"features_1\"], label_multiset[\"features_2\"] = node_features_1, node_features_2\n",
        "\n",
        "        # label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "        #     graph1), nx.adjacency_matrix(graph2)\n",
        "        # label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        # label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        # label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (sum(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 15\n",
        "tensor_neurons = 4\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with SUM Pooling(' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dJq9glo1CWUH",
        "outputId": "9775fb10-aee0-4c54-b64a-d7c4d741b190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.1593770831823349\n",
            "Iteration 1 loss:  0.15329834818840027\n",
            "Iteration 2 loss:  0.14275172352790833\n",
            "Iteration 3 loss:  0.1523127406835556\n",
            "Iteration 4 loss:  0.14428897202014923\n",
            "Iteration 5 loss:  0.13096500933170319\n",
            "Iteration 6 loss:  0.12275111675262451\n",
            "Iteration 7 loss:  0.13100720942020416\n",
            "Iteration 8 loss:  0.1222509816288948\n",
            "Iteration 9 loss:  0.1294388473033905\n",
            "Iteration 10 loss:  0.1204586997628212\n",
            "Iteration 11 loss:  0.1206701248884201\n",
            "Iteration 12 loss:  0.11395935714244843\n",
            "Iteration 13 loss:  0.1130850538611412\n",
            "Iteration 14 loss:  0.11288636177778244\n",
            "Iteration 15 loss:  0.10645580291748047\n",
            "Iteration 16 loss:  0.10625042021274567\n",
            "Iteration 17 loss:  0.1136157289147377\n",
            "Iteration 18 loss:  0.110967718064785\n",
            "Iteration 19 loss:  0.089595894018809\n",
            "Iteration 20 loss:  0.10275425016880035\n",
            "Iteration 21 loss:  0.10204027593135834\n",
            "Iteration 22 loss:  0.1033082902431488\n",
            "Iteration 23 loss:  0.10462445765733719\n",
            "Iteration 24 loss:  0.09420356899499893\n",
            "Iteration 25 loss:  0.10465852916240692\n",
            "Iteration 26 loss:  0.10174502432346344\n",
            "Iteration 27 loss:  0.09254845976829529\n",
            "Iteration 28 loss:  0.1039399579167366\n",
            "Iteration 29 loss:  0.10346895456314087\n",
            "Iteration 30 loss:  0.10052046924829483\n",
            "Iteration 31 loss:  0.09954960644245148\n",
            "Iteration 32 loss:  0.09713795781135559\n",
            "Iteration 33 loss:  0.10341249406337738\n",
            "Iteration 34 loss:  0.09858784824609756\n",
            "Iteration 35 loss:  0.08620350062847137\n",
            "Iteration 36 loss:  0.08546380698680878\n",
            "Iteration 37 loss:  0.09245826303958893\n",
            "Iteration 38 loss:  0.09150566905736923\n",
            "Iteration 39 loss:  0.08466599384943645\n",
            "Iteration 40 loss:  0.09013151377439499\n",
            "Iteration 41 loss:  0.0986969918012619\n",
            "Iteration 42 loss:  0.08875773102045059\n",
            "Iteration 43 loss:  0.09293593466281891\n",
            "Iteration 44 loss:  0.09128797799348831\n",
            "Iteration 45 loss:  0.09199348837137222\n",
            "Iteration 46 loss:  0.0933854728937149\n",
            "Iteration 47 loss:  0.08633508533239365\n",
            "Iteration 48 loss:  0.084815613925457\n",
            "Iteration 49 loss:  0.080539271235466\n",
            "Iteration 50 loss:  0.09165240824222565\n",
            "Iteration 51 loss:  0.08431120216846466\n",
            "Iteration 52 loss:  0.09088298678398132\n",
            "Iteration 53 loss:  0.08743172883987427\n",
            "Iteration 54 loss:  0.0841476321220398\n",
            "Iteration 55 loss:  0.09120722115039825\n",
            "Iteration 56 loss:  0.07361996918916702\n",
            "Iteration 57 loss:  0.08486458659172058\n",
            "Iteration 58 loss:  0.09042056649923325\n",
            "Iteration 59 loss:  0.09241644541422527\n",
            "Iteration 60 loss:  0.08334103226661682\n",
            "Iteration 61 loss:  0.08068399876356125\n",
            "Iteration 62 loss:  0.08693230152130127\n",
            "Iteration 63 loss:  0.0834636315703392\n",
            "Iteration 64 loss:  0.0868835300207138\n",
            "Iteration 65 loss:  0.08158048242330551\n",
            "Iteration 66 loss:  0.08818960189819336\n",
            "Iteration 67 loss:  0.07682567089796066\n",
            "Iteration 68 loss:  0.08200101554393768\n",
            "Iteration 69 loss:  0.08275511860847473\n",
            "Iteration 70 loss:  0.08760056644678116\n",
            "Iteration 71 loss:  0.07303658127784729\n",
            "Iteration 72 loss:  0.07733187079429626\n",
            "Iteration 73 loss:  0.07895564287900925\n",
            "Iteration 74 loss:  0.08238058537244797\n",
            "Iteration 75 loss:  0.08988465368747711\n",
            "Iteration 76 loss:  0.07633421570062637\n",
            "Iteration 77 loss:  0.08017177134752274\n",
            "Iteration 78 loss:  0.08198624849319458\n",
            "Iteration 79 loss:  0.07877125839392345\n",
            "Iteration 80 loss:  0.07609733939170837\n",
            "Iteration 81 loss:  0.08723507076501846\n",
            "Iteration 82 loss:  0.0812656357884407\n",
            "Iteration 83 loss:  0.08773385733366013\n",
            "Iteration 84 loss:  0.07607907056808472\n",
            "Iteration 85 loss:  0.07817047089338303\n",
            "Iteration 86 loss:  0.07783310115337372\n",
            "Iteration 87 loss:  0.07554694265127182\n",
            "Iteration 88 loss:  0.06955591589212418\n",
            "Iteration 89 loss:  0.07588834563891093\n",
            "Iteration 90 loss:  0.07982856780290604\n",
            "Iteration 91 loss:  0.07619243115186691\n",
            "Iteration 92 loss:  0.07954399287700653\n",
            "Iteration 93 loss:  0.08885332196950912\n",
            "Iteration 94 loss:  0.06780283898115158\n",
            "Iteration 95 loss:  0.07014264911413193\n",
            "Iteration 96 loss:  0.07482635974884033\n",
            "Iteration 97 loss:  0.07930141687393188\n",
            "Iteration 98 loss:  0.07771486043930054\n",
            "Iteration 99 loss:  0.06643025577068329\n",
            "Iteration 100 loss:  0.07247759401798248\n",
            "Iteration 101 loss:  0.07625424116849899\n",
            "Iteration 102 loss:  0.0730084553360939\n",
            "Iteration 103 loss:  0.08228586614131927\n",
            "Iteration 104 loss:  0.06815608590841293\n",
            "Iteration 105 loss:  0.07201343774795532\n",
            "Iteration 106 loss:  0.06820607930421829\n",
            "Iteration 107 loss:  0.06711380928754807\n",
            "Iteration 108 loss:  0.08236722648143768\n",
            "Iteration 109 loss:  0.07890822490056355\n",
            "Iteration 110 loss:  0.06373351067304611\n",
            "Iteration 111 loss:  0.06757275015115738\n",
            "Iteration 112 loss:  0.061764154583215714\n",
            "Iteration 113 loss:  0.06512056291103363\n",
            "Iteration 114 loss:  0.05707874149084091\n",
            "Iteration 115 loss:  0.04926072433590889\n",
            "Iteration 116 loss:  0.05698009952902794\n",
            "Iteration 117 loss:  0.04714149609208107\n",
            "Iteration 118 loss:  0.04488775134086609\n",
            "Iteration 119 loss:  0.039220020174980164\n",
            "Iteration 120 loss:  0.02791621722280979\n",
            "Iteration 121 loss:  0.03584729880094528\n",
            "Iteration 122 loss:  0.03698175773024559\n",
            "Iteration 123 loss:  0.02735307067632675\n",
            "Iteration 124 loss:  0.03845733031630516\n",
            "Iteration 125 loss:  0.027704555541276932\n",
            "Iteration 126 loss:  0.03261210024356842\n",
            "Iteration 127 loss:  0.03202498331665993\n",
            "Iteration 128 loss:  0.02802477777004242\n",
            "Iteration 129 loss:  0.020326465368270874\n",
            "Iteration 130 loss:  0.02253890037536621\n",
            "Iteration 131 loss:  0.024714309722185135\n",
            "Iteration 132 loss:  0.024883130565285683\n",
            "Iteration 133 loss:  0.029373520985245705\n",
            "Iteration 134 loss:  0.024807428941130638\n",
            "Iteration 135 loss:  0.025953058153390884\n",
            "Iteration 136 loss:  0.023958375677466393\n",
            "Iteration 137 loss:  0.02252272702753544\n",
            "Iteration 138 loss:  0.020323986187577248\n",
            "Iteration 139 loss:  0.017636381089687347\n",
            "Iteration 140 loss:  0.02136717550456524\n",
            "Iteration 141 loss:  0.01757141761481762\n",
            "Iteration 142 loss:  0.017902133986353874\n",
            "Iteration 143 loss:  0.018442003056406975\n",
            "Iteration 144 loss:  0.01635022833943367\n",
            "Iteration 145 loss:  0.017033591866493225\n",
            "Iteration 146 loss:  0.015873562544584274\n",
            "Iteration 147 loss:  0.019566873088479042\n",
            "Iteration 148 loss:  0.012615757994353771\n",
            "Iteration 149 loss:  0.017806842923164368\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.1017417454660344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GinYFvaCWIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}